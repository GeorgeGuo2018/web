<!doctype html><html lang=zh class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.83.1"><link rel=canonical type=text/html href=/web/zh/docs/installation/><meta name=ROBOTS content="NOINDEX, NOFOLLOW"><link rel="shortcut icon" href=/web/favicons/favicon.ico><link rel=apple-touch-icon href=/web/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/web/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/web/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/web/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/web/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/web/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/web/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/web/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/web/favicons/android-192x192.png sizes=192x192><title>部署 | Tkestack</title><meta name=description content="生产级别多集群管理系统"><meta property="og:title" content="部署"><meta property="og:description" content="部署架构， 环境要求， 部署步骤
"><meta property="og:type" content="website"><meta property="og:url" content="/web/zh/docs/installation/"><meta property="og:site_name" content="Tkestack"><meta itemprop=name content="部署"><meta itemprop=description content="部署架构， 环境要求， 部署步骤
"><meta name=twitter:card content="summary"><meta name=twitter:title content="部署"><meta name=twitter:description content="部署架构， 环境要求， 部署步骤
"><link rel=preload href=/web/scss/main.min.f3f5e11928ea652eef8f11ab959efa477bbd1a85923ff5e0245c83fe74bd312a.css as=style><link href=/web/scss/main.min.f3f5e11928ea652eef8f11ab959efa477bbd1a85923ff5e0245c83fe74bd312a.css rel=stylesheet integrity><script src=https://code.jquery.com/jquery-3.5.1.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script></head><body class=td-section><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar"><a class=navbar-brand href=/web/zh/><span class=navbar-logo></span><span class="text-uppercase font-weight-bold">Tkestack</span></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/web/zh/docs/><span>Docs</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/web/zh/blog/><span>Blog</span></a></li><li class="nav-item dropdown d-none d-lg-block"><a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>中文 Chinese</a><div class=dropdown-menu aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=/web/>English</a></div></li></ul></div><div class="navbar-nav d-none d-lg-block"></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><div class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none"></div><div class="d-none d-xl-block col-xl-2 td-toc d-print-none"></div><main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>这是本节的多页打印视图。
<a href=# onclick="return print(),!1">点击此处打印</a>.</p><p><a href=/web/zh/docs/installation/>返回本页常规视图</a>.</p></div><h1 class=title>部署</h1><div class=lead>部署架构， 环境要求， 部署步骤</div><ul><li>1: <a href=#pg-f6d1bc768009a5736551eb833bad5d9e>产品部署架构</a></li><li>2: <a href=#pg-772f3961b57805af450afc37610035eb>部署环境要求</a></li><li>3: <a href=#pg-783c8ecc2ba7ee0bcac796c85b13d77a>安装使用 GPU</a></li><li>4: <a href=#pg-51fdfea303f27cb5db555430fe8fe2d5>迁移步骤</a></li><li>5: <a href=#pg-bc59bbbdb54b32c83e332a5bb22589a2>安装步骤</a></li><li>6: <a href=#pg-675ad318dc95d5a2edd69400c4712727></a></li></ul><div class=content></div></div><div class=td-content><h1 id=pg-f6d1bc768009a5736551eb833bad5d9e>1 - 产品部署架构</h1><div class=lead>产品部署架构描述</div><h2 id=总体架构>总体架构</h2><p>TKEStack 产品架构如下图所示：</p><p><img src=./images/tkestackhighlevelarchitecture-2x.png alt></p><h2 id=架构说明>架构说明</h2><p>TKEStack 采用了 Kubernetes on Kubernetes 的设计理念。即节点仅运行 Kubelet 进程，其他组件均采用容器化部署，由 Kubernetes 进行管理。</p><p>架构上分为 Global 集群和业务集群。Global 集群运行整个容器服务开源版平台自身所需要的组件，业务集群运行用户业务。在实际的部署过程中，可根据实际情况进行调整。</p><h2 id=模块说明>模块说明</h2><ul><li>Installer: 运行 tke-installer 安装器的节点，用于提供 Web UI 指导用户在 Global 集群部署TKEStacl控制台；</li><li>Global Cluster: 运行的 TKEStack 控制台的 Kubernetes 集群；</li><li>Cluster: 运行业务的 Kubernetes 集群，可以通过 TKEStack 控制台创建或导入；</li><li>Auth: 权限认证组件，提供用户鉴权、权限对接相关功能；</li><li>Gateway: 网关组件，实现集群后台统一入口、统一鉴权相关的功能，并运行控制台的 Web 界面服务；</li><li>Platform: 集群管理组件，提供 Global 集群管理多个业务集群相关功能；</li><li>Business: 业务管理组件，提供平台业务管理相关功能的后台服务；</li><li>Network Controller：网络服务组件，支撑 Galaxy 网络功能；</li><li>Monitor: 监控服务组件，提供监控采集、上报、告警相关服务；</li><li>Notify: 通知功能组件，提供消息通知相关的功能；</li><li>Registry: 镜像服务组件，提供平台镜像仓库服务；</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-772f3961b57805af450afc37610035eb>2 - 部署环境要求</h1><div class=lead>部署环境要求</div><h2 id=硬件要求>硬件要求</h2><blockquote><p><strong>特别注意</strong>：</p><ol><li><p>安装的时候，至少需要<strong>一个 Installer 节点</strong>和<strong>一个作为 Global 集群的 master 节点</strong>共<strong>两个节点</strong>。
>
> v1.3.0 之后的版本可直接使用 All-In-One 的安装模式，此时 Installer 节点也可以作为 Global 集群的节点。但注意：此时 Installer 的节点配置要以 Global 集群的节点配置为准，否则 Installer 节点配置太低很容易安装失败。另外该功能还不是很成熟，为避免安装失败，尽量<strong>将 Installer 节点和 Global 节点分开始用</strong></p></li><li><p><strong>Installer 节点</strong>：是单独的用作安装的节点，不能作为 Global 集群的节点使用。因为在安装 Global 集群时，需要多次重启 docker，此时如果 Global 集群里面有 Installer 节点，重启 docker 会中断 Global 集群的安装。该节点需要一台<strong>系统盘 100G</strong> 的机器，系统盘要保证剩余 <strong>50GB 可用的空间</strong>。
>
> <strong>v1.3.0 之后 Installer 节点支持作为 Global 集群的节点使用，但注意此时 Installer 节点配置以 Global 集群的节点为准</strong></p></li><li><p><strong>Global 集群</strong>：至少需要一台 <strong>8核16G内存，100G系统盘</strong>的机器。</p></li><li><p><strong>业务集群</strong>：业务集群是在部署完 Global 集群之后再添加的。</p></li></ol></blockquote><ul><li><strong>最小化部署硬件配置：</strong></li></ul><table><thead><tr><th style=text-align:left><strong>安装/业务集群</strong></th><th style=text-align:left><strong>节点/集群</strong></th><th style=text-align:left><strong>CPU 核数</strong></th><th style=text-align:left><strong>内存</strong></th><th style=text-align:left><strong>系统盘</strong></th><th style=text-align:left><strong>数量</strong></th></tr></thead><tbody><tr><td style=text-align:left>安装</td><td style=text-align:left>Installer 节点</td><td style=text-align:left>1</td><td style=text-align:left>2G</td><td style=text-align:left>100G</td><td style=text-align:left>1</td></tr><tr><td style=text-align:left>TKEStack 控制台</td><td style=text-align:left>Global 集群</td><td style=text-align:left>8</td><td style=text-align:left>16G</td><td style=text-align:left>100G</td><td style=text-align:left>1</td></tr><tr><td style=text-align:left>业务集群</td><td style=text-align:left>Master & ETCD</td><td style=text-align:left>4</td><td style=text-align:left>8G</td><td style=text-align:left>100G</td><td style=text-align:left>1</td></tr><tr><td style=text-align:left>业务集群</td><td style=text-align:left>Node</td><td style=text-align:left>8</td><td style=text-align:left>16G</td><td style=text-align:left>100G</td><td style=text-align:left>3</td></tr></tbody></table><ul><li><strong>推荐硬件配置：</strong></li></ul><table><thead><tr><th style=text-align:left><strong>安装/业务集群</strong></th><th style=text-align:left><strong>节点/集群</strong></th><th style=text-align:left><strong>CPU 核数</strong></th><th style=text-align:left><strong>内存</strong></th><th style=text-align:left><strong>系统盘</strong></th><th style=text-align:left><strong>数量</strong></th></tr></thead><tbody><tr><td style=text-align:left>安装</td><td style=text-align:left>Installer 节点</td><td style=text-align:left>1</td><td style=text-align:left>2G</td><td style=text-align:left>100G</td><td style=text-align:left>1</td></tr><tr><td style=text-align:left>TKEStack 控制台</td><td style=text-align:left>Global 节点</td><td style=text-align:left>8</td><td style=text-align:left>16G</td><td style=text-align:left>100G SSD</td><td style=text-align:left>3</td></tr><tr><td style=text-align:left>业务集群</td><td style=text-align:left>Master & ETCD</td><td style=text-align:left>16</td><td style=text-align:left>32G</td><td style=text-align:left>300G SSD</td><td style=text-align:left>3</td></tr><tr><td style=text-align:left>业务集群</td><td style=text-align:left>Node</td><td style=text-align:left>16</td><td style=text-align:left>32G</td><td style=text-align:left>系统盘：100G 数据盘：300G （/var/lib/docker）</td><td style=text-align:left>>3</td></tr></tbody></table><blockquote><p>注意：上表中的<strong>数据盘</strong>（/var/lib/docker）表示的是 docker 相关信息在主机中存储的位置，即<strong>容器数据盘</strong>，包括 docker 的镜像、容器、日志（如果容器的日志文件所在路径没有挂载 volume，日志文件会被写入容器可写层，落盘到容器数据盘里）等文件。建议给此路径挂盘，避免与系统盘混用，避免因容器、镜像、日志等 docker 相关信息导致磁盘压力过大。</p></blockquote><h2 id=软件要求>软件要求</h2><blockquote><p><strong>注意，以下要求针对集群中的所有节点</strong></p></blockquote><table><thead><tr><th style=text-align:left>需求项</th><th style=text-align:left>具体要求</th><th style=text-align:left>命令参考 （以 CentOS 7.6为例）</th></tr></thead><tbody><tr><td style=text-align:left>操作系统</td><td style=text-align:left>Ubuntu 16.04/18.04 LTS (64-bit)<br>CentOS Linux 7.6 (64-bit) Tencent Linux 2.2</td><td style=text-align:left><code>cat /etc/redhat-release</code></td></tr><tr><td style=text-align:left>kernel 版本</td><td style=text-align:left>>= Kernel 3.10.0-957.10.1.el7.x86_64</td><td style=text-align:left><code>uname -sr</code></td></tr><tr><td style=text-align:left>ssh sudo yum CLI</td><td style=text-align:left>确保 Installer 节点及其容器、<br>Global 集群节点及其容器、<br>业务集群节点及其容器&mldr;之间能够 ssh 互联；<br>确保每个节点都有基础工具</td><td style=text-align:left>1. 确保在添加所有节点时，IP 和密码输入正确。<br>2. 确保每个节点都有 sudo 或 root 权限<br>3. 如果是 CentOS，确保拥有 yum；其他操作系统类似，确保拥有包管理器<br>4. 确保拥有命令行工具</td></tr><tr><td style=text-align:left>Swap</td><td style=text-align:left>关闭。 如果不满足，系统会有一定几率出现 io 飙升，造成 docker 卡死。kubelet 会启动失败<br>(可以设置 kubelet 启动参数 &ndash;fail-swap-on 为 false 关闭 swap 检查)</td><td style=text-align:left><code>sudo swapoff -a</code><br><code>sudo sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab</code><br><code># 注意：如果 /etc/fstab有挂载 swap，必须要注释掉，不然重新开机时又会重新挂载 swap</code></td></tr><tr><td style=text-align:left>防火墙</td><td style=text-align:left>关闭。 或者至少要放通22、80、8080、443、6443、2379、2380、10250-10255、31138 端口</td><td style=text-align:left><code>可通过以下关闭防火墙</code><br><code>systemctl stop firewalld && systemctl disable firewalld</code><br><code>或者通过以下命令放通指定端口，例如只放通80端口</code> <code>firewall-cmd --zone=public --add-port=80/tcp --permanent</code></td></tr><tr><td style=text-align:left>SELinux</td><td style=text-align:left>关闭。 Kubernetes 官方要求，否则 kubelet 挂载目录时可能报错 <code>Permission denied</code></td><td style=text-align:left><code>setenforce 0</code><br><code>sed -i "s/SELINUX=enforcing/SELINUX=disabled/g" /etc/selinux/config</code></td></tr><tr><td style=text-align:left>时区</td><td style=text-align:left>所有服务器时区必须统一，建议设置为 <code>Asia/Shanghai</code></td><td style=text-align:left><code>timedatectl set-timezone Asia/Shanghai</code></td></tr><tr><td style=text-align:left>时间同步</td><td style=text-align:left>ETCD 集群各机器需要时间同步，可以利用 chrony 用于系统时间同步；<br>所有服务器要求时间必须同步，误差不得超过 2 秒</td><td style=text-align:left><code>yum install -y chronyd</code><br><code>systemctl enable chronyd && systemctl start chronyd</code></td></tr><tr><td style=text-align:left>路由检查</td><td style=text-align:left>有些设备可能会默认配置一些路由，这些路由可能与 TKEStack 冲突，建议删除这些路由并做相关配置</td><td style=text-align:left><code>ip link delete docker0</code><br><code>ip link add name docker0 type bridge</code><br><code>ip addr add dev docker0 172.17.0.1/16</code></td></tr><tr><td style=text-align:left>docker 检查</td><td style=text-align:left>有些设备可能会默认安装 docker，该 docker 版本可能与 TKEStack 不一致，<br>建议在安装 TKEStack 之前删除docker</td><td style=text-align:left><code>yum remove docker-ce containerd docker-ce-cli -y</code></td></tr></tbody></table></div><div class=td-content style=page-break-before:always><h1 id=pg-783c8ecc2ba7ee0bcac796c85b13d77a>3 - 安装使用 GPU</h1><div class=lead>安装使用 GPU 具体步骤，注意事项</div><h1 id=安装使用步骤>安装使用步骤</h1><h2 id=安装使用步骤-1>安装使用步骤</h2><h3 id=限制条件>限制条件</h3><ul><li>用户在安装使用GPU时，要求集群内必须包含GPU机型节点</li><li>该组件基于 Kubernetes DevicePlugin 实现，只能运行在支持 DevicePlugin 的 kubernetes版本（Kubernetes 1.10 之上的版本）</li><li>GPU-Manager 将每张 GPU 卡视为一个有100个单位的资源：当前仅支持 0-1 的小数张卡，如 20、35、50；以及正整数张卡，如200、500等；不支持类似150、250的资源请求；显存资源是以 256MiB 为最小的一个单位的分配显存</li></ul><h3 id=tkestack-支持的-gpu-类型>TKEStack 支持的 GPU 类型</h3><p>TKEStack目前支持两种GPU类型：</p><ul><li>vGPU：虚拟GPU类型(Virtual GPU)，当选择安装此类型的GPU时，平台会自动安装组件<a href=https://github.com/tkestack/gpu-manager>GPUManager</a>，对应在集群中部署的kubernetes资源对象如下：</li></ul><table><thead><tr><th>kubernetes 对象名称</th><th>类型</th><th>建议预留资源</th><th>所属 Namespaces</th></tr></thead><tbody><tr><td>gpu-manager-daemonset</td><td>DaemonSet</td><td>每节点1核 CPU, 1Gi内存</td><td>kube-system</td></tr><tr><td>gpu-quota-admission</td><td>Deployment</td><td>1核 CPU, 1Gi内存</td><td>kube-system</td></tr></tbody></table><ul><li>pGPU: 物理GPU类型(Physical GPU)，当选择安装此类型的GPU时，平台会自动安装组件<a href=https://github.com/NVIDIA/k8s-device-plugin>Nvidia-k8s-device-plugin</a>，对应的在集群中部署的kubernetes资源对象如下：</li></ul><table><thead><tr><th>kubernetes 对象名称</th><th>类型</th><th>建议预留资源</th><th>所属 Namespaces</th></tr></thead><tbody><tr><td>nvidia-device-plugin-daemonset</td><td>DaemonSet</td><td>每节点1核 CPU, 1Gi内存</td><td>kube-system</td></tr></tbody></table><h3 id=安装步骤>安装步骤</h3><h4 id=安装使用-vgpu>安装使用 vGPU</h4><p>用户在新建独立集群时，勾选GPU选项，在下拉选项中选择 vGPU，如下图所示：</p><p><img src=../images/gpu-1.png alt></p><p>目标机器部分，勾选GPU选项，平台会自动为节点安装GPU驱动，如下图所示：</p><p><img src=../images/gpu-2.png alt></p><p>等待新建独立集群处于running状态后，可以通过登陆到集群节点通过<code>kubectl</code>查看在集群<code>kube-system</code>命名空间中部署了<code>gpu-manager</code>和<code>gpu-quota-admission</code>两个pod：</p><pre><code># kubectl get pods -n kube-system | grep gpu
gpu-manager-daemonset-2vvbm              1/1     Running   0          2m13s
gpu-quota-admission-76cfff49b6-vdh42     1/1     Running   0          3m2s
</code></pre><h4 id=创建使用-vgpu-的工作负载>创建使用 vGPU 的工作负载</h4><p>TKEStack创建使用GPU的工作负载支持两种方式：第一种是通过TKEStack前端页面创建，第二种是通过后台命令行的方式创建。</p><p>1、 通过前端控制台创建</p><p>在安装了 GPU-Manager 的集群中，创建工作负载时可以设置GPU限制，如下图所示：</p><blockquote><p>注意：</p><ol><li>卡数只能填写 0.1 到 1 之间的两位小数或者是所有自然数，例如：0、0.3、0.56、0.7、0.9、1、6、34，不支持 1.5、2.7、3.54</li><li>显存只能填写自然数 n，负载使用的显存为 n*256MiB</li></ol></blockquote><p><img src=../images/gpu-3.png alt></p><p>2、 通过后台命令行创建</p><p>使用 YAML 创建使用 GPU 的工作负载，需要在 YAML 文件中为容器设置 GPU 的使用资源。</p><ul><li>CPU 资源需要在 resource 上填写<code>tencent.com/vcuda-core</code></li><li>显存资源需要在 resource 上填写<code>tencent.com/vcuda-memory</code></li></ul><p>如下所示：创建一个使用 0.3 张卡、5GiB 显存的nginx应用（5GiB = 20*256MB）</p><pre><code>apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx
    imagePullPolicy: IfNotPresent
    resources:
      limits:
        tencent.com/vcuda-core: 30
        tencent.com/vcuda-memory: 20
      requests:
        tencent.com/vcuda-core: 30
        tencent.com/vcuda-memory: 20
</code></pre><pre><code># kubectl create -f nginx.yaml
pod/nginx created
</code></pre><blockquote><p>注意：</p><ul><li>如果pod在创建过程中出现CrashLoopBackOff 的状态，且error log如下所示：</li></ul><pre><code>failed to create containerd task: OCI runtime create failed: container_linux.go:380: starting container process caused: process_linux.go:545: container init caused: Running hook #0:: error running hook: exit status 1, stdout: , stderr: nvidia-container-cli: mount error: open failed: /sys/fs/cgroup/devices/system.slice/containerd.service/kubepods-besteffort-podfd3b355a_665c_4c95_8e7f_61fd2111689f.slice/devices.allow: no such file or directory: unknown
</code></pre><p>需要在GPU主机上手动安装libnvidia-container-tools这个组件，首先需要添加repo源：添加repo源， 添加repo源后执行如下命令：</p><pre><code># yum install libnvidia-container-tools
</code></pre><ul><li>如果pod在创建过程中出现如下error log：</li></ul><pre><code>failed to generate spec: lstat /dev/nvidia-uvm: no such file or directory
</code></pre><p>需要在pod所在的主机上手动mount这个设备文件：</p><pre><code># nvidia-modprobe -u -c=0
</code></pre></blockquote><p>查看创建的应用状态：</p><pre><code># kubectl get pods
NAME    READY   STATUS    RESTARTS   AGE
nginx   1/1     Running   0          3s
</code></pre><p>查看GPU监控数据（需要提前安装socat）：</p><pre><code># yum install socat
</code></pre><pre><code># kubectl port-forward svc/gpu-manager-metric -n kube-system 5678:5678
</code></pre><pre><code># curl http://127.0.0.1:5678/metric
</code></pre><p>结果如下</p><pre><code>Handling connection for 5678
# HELP container_gpu_memory_total gpu memory usage in MiB
# TYPE container_gpu_memory_total gauge
container_gpu_memory_total{container_name=&quot;nginx&quot;,gpu_memory=&quot;gpu0&quot;,namespace=&quot;default&quot;,node=&quot;10.0.0.127&quot;,pod_name=&quot;nginx&quot;} 0
container_gpu_memory_total{container_name=&quot;nginx&quot;,gpu_memory=&quot;total&quot;,namespace=&quot;default&quot;,node=&quot;10.0.0.127&quot;,pod_name=&quot;nginx&quot;} 0
# HELP container_gpu_utilization gpu utilization
# TYPE container_gpu_utilization gauge
container_gpu_utilization{container_name=&quot;nginx&quot;,gpu=&quot;gpu0&quot;,namespace=&quot;default&quot;,node=&quot;10.0.0.127&quot;,pod_name=&quot;nginx&quot;} 0
container_gpu_utilization{container_name=&quot;nginx&quot;,gpu=&quot;total&quot;,namespace=&quot;default&quot;,node=&quot;10.0.0.127&quot;,pod_name=&quot;nginx&quot;} 0
# HELP container_request_gpu_memory request of gpu memory in MiB
# TYPE container_request_gpu_memory gauge
container_request_gpu_memory{container_name=&quot;nginx&quot;,namespace=&quot;default&quot;,node=&quot;10.0.0.127&quot;,pod_name=&quot;nginx&quot;,req_of_gpu_memory=&quot;total&quot;} 5120
# HELP container_request_gpu_utilization request of gpu utilization
# TYPE container_request_gpu_utilization gauge
container_request_gpu_utilization{container_name=&quot;nginx&quot;,namespace=&quot;default&quot;,node=&quot;10.0.0.127&quot;,pod_name=&quot;nginx&quot;,req_of_gpu=&quot;total&quot;} 0.30000001192092896
</code></pre><h4 id=安装使用-pgpu>安装使用 pGPU</h4><p>用户在新建独立集群时，勾选GPU选项，在下拉选项中选择pGPU，如下图所示：</p><p><img src=../images/gpu-4.png alt></p><p>目标机器部分，勾选GPU选项，平台会自动为节点安装GPU驱动，如下图所示：</p><p><img src=../images/gpu-2.png alt></p><p>等待新建独立集群处于running状态后，可以通过登陆到集群节点通过<code>kubectl</code>查看到，在集群<code>kube-system</code>命名空间中部署了<code>nvidia-device-plugin</code>pod：</p><pre><code># kubectl get pods -n kube-system | grep nvidia
nvidia-device-plugin-daemonset-frdh2     1/1     Running   0          64s
</code></pre><p>通过查看节点信息可以看到GPU资源和使用情况：</p><pre><code># kubectl describe nodes &lt;nodeIP&gt;
</code></pre><p>显示信息如下：</p><pre><code>Capacity:
  cpu:                8
  ephemeral-storage:  154685884Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             32779608Ki
  nvidia.com/gpu:     1
  pods:               256
Allocatable:
  cpu:                7800m
  ephemeral-storage:  142558510459
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             31653208Ki
  nvidia.com/gpu:     1
  pods:               256
</code></pre><h4 id=创建使用vgpu的工作负载>创建使用vGPU的工作负载</h4><ul><li><p>通过控制台创建方式参考vGPU的创建步骤</p></li><li><p>通过命令行创建</p></li></ul><p>通过如下YAML创建使用1个GPU的工作负载：</p><pre><code>apiVersion: v1
kind: Pod
metadata:
  name: gpu-operator-test
spec:
  restartPolicy: OnFailure
  containers:
    - name: cuda-vector-add
      image: &quot;tkestack/cuda-vector-add:v0.1&quot;
      resources:
        limits:
          nvidia.com/gpu: 1
</code></pre><pre><code># kubectl create -f pod.yaml
pod/gpu-operator-test created
</code></pre><p>查看pod的状态和log：</p><pre><code># kubectl get pods
NAME                READY   STATUS      RESTARTS   AGE
gpu-operator-test   0/1     Completed   0          4m51s
</code></pre><pre><code># kubectl logs gpu-operator-test
[Vector addition of 50000 elements]
Copy input data from the host memory to the CUDA device
CUDA kernel launch with 196 blocks of 256 threads
Copy output data from the CUDA device to the host memory
Test PASSED
Done
</code></pre><p>通过再次查看节点信息可以看到GPU已经被分配使用：</p><pre><code>kubectl describe nodes &lt;nodeIP&gt;
</code></pre><pre><code>Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests     Limits
  --------           --------     ------
  cpu                1137m (14%)  282m (3%)
  memory             644Mi (2%)   1000Mi (3%)
  ephemeral-storage  0 (0%)       0 (0%)
  hugepages-1Gi      0 (0%)       0 (0%)
  hugepages-2Mi      0 (0%)       0 (0%)
  nvidia.com/gpu     1            1
</code></pre><h4 id=添加节点使用gpu>添加节点使用GPU</h4><p>在添加节点上使用GPU资源，需要在创建添加节点时勾选GPU选项，如下图所示：</p><p><img src=../images/gpu-5.png alt></p></div><div class=td-content style=page-break-before:always><h1 id=pg-51fdfea303f27cb5db555430fe8fe2d5>4 - 迁移步骤</h1><div class=lead>TKEStack 具体迁移步骤，注意事项</div><h2 id=容器运行时迁移>容器运行时迁移</h2><p><a href=https://tkestack.github.io/web/zh/blog/2021/09/01/container-runtime-migraion/>TKEStack 集群容器运行时迁移</a></p></div><div class=td-content style=page-break-before:always><h1 id=pg-bc59bbbdb54b32c83e332a5bb22589a2>5 - 安装步骤</h1><div class=lead>tke stack 具体安装步骤，注意事项</div><h1 id=安装步骤>安装步骤</h1><h2 id=安装步骤-1>安装步骤</h2><h3 id=1-需求检查>1. 需求检查</h3><p>仔细检查每个节点的硬件和软件需求：<a href=environment-requirement.md>installation requirements</a></p><h3 id=2-installer安装>2. Installer安装</h3><p>为了简化平台安装过程，容器服务开源版基于 tke-installer 安装器提供了一个向导式的图形化安装指引界面。</p><p>在您 Installer 节点的终端，执行如下脚本：</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text># amd64
arch=amd64 version=v1.3.1 &amp;&amp; wget https://tke-release-1251707795.cos.ap-guangzhou.myqcloud.com/tke-installer-linux-$arch-$version.run{,.sha256} &amp;&amp; sha256sum --check --status tke-installer-linux-$arch-$version.run.sha256 &amp;&amp; chmod +x tke-installer-linux-$arch-$version.run &amp;&amp; ./tke-installer-linux-$arch-$version.run

# arm64
arch=arm64 version=v1.3.1 &amp;&amp; wget https://tke-release-1251707795.cos.ap-guangzhou.myqcloud.com/tke-installer-linux-$arch-$version.run{,.sha256} &amp;&amp; sha256sum --check --status tke-installer-linux-$arch-$version.run.sha256 &amp;&amp; chmod +x tke-installer-linux-$arch-$version.run &amp;&amp; ./tke-installer-linux-$arch-$version.run
</code></pre></div><blockquote><p>您可以查看 TKEStack <a href=https://github.com/tkestack/tke/releases>Release</a> 按需选择版本进行安装，建议您安装最新版本。</p><p>tke-installer 约为 7GB，包含安装所需的所有资源。</p></blockquote><p>以上脚本执行完之后，终端会提示访问 <a href=http://%5Btke-installer-IP%5D:8080/index.html%EF%BC%8C%E4%BD%BF%E7%94%A8%E6%9C%AC%E5%9C%B0%E4%B8%BB%E6%9C%BA%E7%9A%84%E6%B5%8F%E8%A7%88%E5%99%A8%E8%AE%BF%E9%97%AE%E8%AF%A5%E5%9C%B0%E5%9D%80%EF%BC%8C%E6%8C%89%E7%85%A7%E6%8C%87%E5%BC%95%E5%BC%80%E5%A7%8B%E5%AE%89%E8%A3%85%E6%8E%A7%E5%88%B6%E5%8F%B0%EF%BC%8C%E5%8F%AF%E5%8F%82%E8%80%83%E4%B8%8B%E9%9D%A2%E7%9A%84%E6%8E%A7%E5%88%B6%E5%8F%B0%E5%AE%89%E8%A3%85%E3%80%82>http://[tke-installer-IP]:8080/index.html，使用本地主机的浏览器访问该地址，按照指引开始安装控制台，可参考下面的控制台安装。</a></p><blockquote><p>注意：这里<code>tke-installer-IP</code>地址默认为<strong>内网地址</strong>，如果本地主机不在集群内网，<code>tke-installer-IP</code>为内网地址所对应的<strong>外网地址</strong>。</p></blockquote><h3 id=3-控制台安装>3. 控制台安装</h3><blockquote><p>注意：控制台是运行在global集群之上，控制台安装就是在安装global集群。</p></blockquote><ol><li>填写 TKEStack 控制台基本配置信息</li></ol><p><img src=../images/step-1.png alt></p><ul><li><strong>用户名</strong>：TKEStack 控制台管理员名称（<strong>例如：admin</strong>）</li><li><strong>密码</strong>：TKEStack 控制台管理员密码</li><li><strong>高可用设置</strong>（按需使用，可直接选择【<strong>不设置</strong>】）<ul><li><strong>TKE提供</strong>：在所有 master 节点额外安装 Keepalived 完成 VIP 的配置与连接</li><li><strong>使用已有</strong>：对接配置好的外部 LB 实例</li><li><strong>不设置</strong>：访问第一台 master 节点 APIServer</li></ul></li><li>填写 TKEStack 控制台集群设置信息</li></ul><p><img src=../images/step-2.png alt></p><ul><li><strong>网卡名称</strong>：集群节点使用的网卡，根据实际环境填写正确的网卡名称，默认为eth0（<strong>建议使用默认值</strong>）</li><li><strong>GPU 类型</strong>：（按需使用，可直接选择【<strong>不设置</strong>】）<ul><li><strong>不使用</strong>：不安装 Nvidia GPU 相关驱动</li><li><strong>Virtual</strong>：平台会自动为集群安装 <a href=../key-features/gpumanager.md>GPUManager</a> 扩展组件</li><li><strong>Physical</strong>：平台会自动为集群安装 <a href=https://github.com/NVIDIA/k8s-device-plugin>Nvidia-k8s-device-plugin</a></li></ul></li><li><strong>容器网络：</strong> 将为集群内容器分配在容器网络地址范围内的 IP 地址，您可以自定义三大私有网段作为容器网络， 根据您选择的集群内服务数量的上限，自动分配适当大小的 CIDR 段用于 Kubernetes service；根据您选择 Pod 数量上限/节点，自动为集群内每台服务器分配一个适当大小的网段用于该主机分配 Pod 的 IP 地址（<strong>建议使用默认值</strong>）<ul><li><strong>CIDR：</strong> 集群内 Sevice、 Pod 等资源所在网段</li><li><strong>Pod数量上限/节点：</strong> 决定分配给每个 Node 的 CIDR 的大小</li><li><strong>Service数量上限/集群</strong>：决定分配给 Sevice 的 CIDR 大小</li></ul></li><li><strong>master 节点：</strong> 输入目标机器信息后单击保存，若保存按钮是灰色，单击网页空白处即可变蓝<ul><li><strong>访问地址：</strong> Master 节点<strong>内网 IP</strong>，请配置<strong>至少 8 Cores & 16G内存</strong> 及以上的机型，<strong>否则会部署失败</strong></li><li><strong>SSH 端口</strong>：请确保目标机器安全组开放 SSH 端口和 ICMP 协议，否则无法远程登录和 PING 服务器（建议使用<strong>22</strong>）</li><li><strong>用户名和密码：</strong> 均为添加的节点的用户名和密码</li><li>可以通过节点下面的【添加机器】蓝色字体增加master节点（<strong>按需添加</strong>）</li></ul></li></ul><p><img src=../images/step-3-2.png alt></p><ul><li><strong>高级设置</strong>（非必须）：可以自定义 Global 集群的 Docker、kube-apiserver、kube-controller-manager、kube-scheduler、kubelet 运行参数</li><li>填写 TKEStack 控制台认证信息。（建议使用<strong>TKE提供</strong>）</li></ul><p><img src=../images/step-3-1.png alt></p><ul><li><strong>认证方式：</strong><ul><li><strong>TKE提供</strong>：使用 TKE 自带的认证方式</li><li><strong>OIDC</strong>：使用 OIDC 认证方式，详见 <a href=https://kubernetes.io/docs/reference/access-authn-authz/authentication/#openid-connect-tokens>OIDC</a></li></ul></li><li>填写 TKEStack 控制台镜像仓库信息。（建议使用<strong>TKE提供</strong>）</li></ul><p><img src=../images/step-4.png alt></p><ul><li><strong>镜像仓库类型：</strong><ul><li><strong>TKE提供</strong>：使用 TKE 自带的镜像仓库</li><li><strong>第三方仓库</strong>：对接配置好的外部镜像仓库，此时，TKEStack 将不会再安装镜像仓库，而是使用您提供的镜像仓库作为默认镜像仓库服务</li></ul></li><li>业务设置</li><li>确认是否开启 TKEStack 控制台业务模块。(<strong>建议开启</strong>)</li><li>确实是否开启平台审计功能，审计模块为平台提供了操作记录,用户可以在平台管理进行查询，需用用户提供ES资源。（<strong>按需使用，可不开启</strong>）</li></ul><p><img src=../images/step-5.png alt></p><ol><li>选择 TKEStack 控制台监控存储类型。（建议使用<strong>TKE提供</strong>）</li></ol><p><img src=../images/step-6.png alt></p><ul><li><strong>监控存储类型</strong>：<ul><li><strong>TKE提供</strong>：使用 TKE 自带的 Influxdb 作为存储</li><li><strong>外部 Influxdb</strong>：对接外部的 Influxdb 作为存储</li><li><strong>外部 ES</strong>：对接外部的 Elasticsearch作为存储</li><li><strong>不使用</strong>：不使用监控</li></ul></li><li>确认是否开启 TKEStack 控制台，选择开启则需要填写控制台域名及证书。（<strong>建议使用默认值</strong>）</li></ul><p><img src=../images/step-7.png alt></p><ul><li><strong>监控存储类型</strong>:<ul><li><strong>自签名证书</strong>：使用 TKE 带有的自签名证书</li><li><strong>指定服务器证书</strong>：填写已备案域名的服务器证书</li></ul></li><li>确认 TKEStack 控制台所有配置是否正确。</li></ul><p><img src=../images/step-8.png alt></p><ol><li>开始安装 TKEStack 控制台，安装成功后界面如下，最下面出现【查看指引】的按钮。</li></ol><p><img src=../images/step-9.png alt></p><ol><li>点击【查看指引】，按照指引，在本地主机上添加域名解析，以访问 TKEStack 控制台。</li></ol><p><img src=../images/step-10.png alt></p><ul><li><p><strong>以Linux/MacOS为例</strong>: 在<code>/etc/hosts</code>文件中加入以下两行域名解析</p><ul><li>【IP】 console.tke.com</li><li>【IP】 registry.tke.com</li></ul><blockquote><p>注意：这里域名的【IP】地址默认为<strong>内网地址</strong>，如果本地主机不在集群内网，域名的IP地址应该填该内网地址所对应的<strong>外网地址</strong>。</p></blockquote></li></ul><h3 id=4-访问控制台>4. 访问控制台</h3><p>在本地主机的浏览器地址输入<code>http://console.tke.com</code>,可访问Global集群的控制台界面，输入控制台安装创建的用户名和密码后即可使用TKEStack。</p><h2 id=安装常见问题>安装常见问题</h2><p>安装失败请首先检查硬件和软件需求：<a href=environment-requirement.md>installation requirements</a></p><p>可参考<a href=../faq/installation/>FAQ installation</a>获得更多帮助。</p></div><div class=td-content style=page-break-before:always><h1 id=pg-675ad318dc95d5a2edd69400c4712727>6 -</h1><h1 id=readme>readme</h1><p>Because we can not find resources online with static folder,so use this folder to store image.</p><p>If we fix this issue in the future, then we use static folder rather than this folder.</p></div></main></div></div><footer class="bg-dark py-5 row d-print-none"><div class="container-fluid mx-sm-5"><div class=row><div class="col-6 col-sm-4 text-xs-center order-sm-2"></div><div class="col-6 col-sm-4 text-right text-xs-center order-sm-3"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub><a class=text-white target=_blank rel=noopener href=https://github.com/tkestack/tke aria-label=GitHub><i class="fab fa-github"></i></a></li></ul></div><div class="col-12 col-sm-4 text-center py-2 order-sm-2"><small class=text-white>&copy; 2022 The TKEStack Authors All Rights Reserved</small></div></div></div></footer></div><script src=https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js integrity=sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js integrity=sha384-+YQ4JLhjyBLPDQt//I+STsc9iw4uQqACwlvpslubQzn4u2UU2UFM80nGisd026JF crossorigin=anonymous></script><script src=/web/js/main.min.1911ee3ae98d7d6df3807cd00d8e31ae7d1c08ee0f0bb587529b0483da4e5464.js integrity="sha256-GRHuOumNfW3zgHzQDY4xrn0cCO4PC7WHUpsEg9pOVGQ=" crossorigin=anonymous></script></body></html>