<!doctype html><html lang=zh class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.83.1"><link rel=canonical type=text/html href=/web/zh/docs/><meta name=ROBOTS content="NOINDEX, NOFOLLOW"><link rel="shortcut icon" href=/web/favicons/favicon.ico><link rel=apple-touch-icon href=/web/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/web/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/web/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/web/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/web/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/web/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/web/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/web/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/web/favicons/android-192x192.png sizes=192x192><title>TKEStack 文档 | Tkestack</title><meta name=description content="生产级别多集群管理系统"><meta property="og:title" content="TKEStack 文档"><meta property="og:description" content="生产级别多集群管理系统"><meta property="og:type" content="website"><meta property="og:url" content="/web/zh/docs/"><meta property="og:site_name" content="Tkestack"><meta itemprop=name content="TKEStack 文档"><meta itemprop=description content="生产级别多集群管理系统"><meta name=twitter:card content="summary"><meta name=twitter:title content="TKEStack 文档"><meta name=twitter:description content="生产级别多集群管理系统"><link rel=preload href=/web/scss/main.min.f3f5e11928ea652eef8f11ab959efa477bbd1a85923ff5e0245c83fe74bd312a.css as=style><link href=/web/scss/main.min.f3f5e11928ea652eef8f11ab959efa477bbd1a85923ff5e0245c83fe74bd312a.css rel=stylesheet integrity><script src=https://code.jquery.com/jquery-3.5.1.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script></head><body class=td-section><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar"><a class=navbar-brand href=/web/zh/><span class=navbar-logo></span><span class="text-uppercase font-weight-bold">Tkestack</span></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/web/zh/docs/><span>Docs</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/web/zh/blog/><span>Blog</span></a></li><li class="nav-item dropdown d-none d-lg-block"><a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>中文 Chinese</a><div class=dropdown-menu aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=/web/docs/>English</a></div></li></ul></div><div class="navbar-nav d-none d-lg-block"></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><div class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none"></div><div class="d-none d-xl-block col-xl-2 td-toc d-print-none"></div><main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>这是本节的多页打印视图。
<a href=# onclick="return print(),!1">点击此处打印</a>.</p><p><a href=/web/zh/docs/>返回本页常规视图</a>.</p></div><h1 class=title>TKEStack 文档</h1><ul><li>1: <a href=#pg-6e17e09fffc1050f46600282def85180>简介</a></li><ul></ul><li>2: <a href=#pg-273a1d3f87830cbffaaf95a64d1ab7e6>部署</a></li><ul><li>2.1: <a href=#pg-f6d1bc768009a5736551eb833bad5d9e>产品部署架构</a></li><li>2.2: <a href=#pg-772f3961b57805af450afc37610035eb>部署环境要求</a></li><li>2.3: <a href=#pg-783c8ecc2ba7ee0bcac796c85b13d77a>安装使用 GPU</a></li><li>2.4: <a href=#pg-51fdfea303f27cb5db555430fe8fe2d5>迁移步骤</a></li><li>2.5: <a href=#pg-bc59bbbdb54b32c83e332a5bb22589a2>安装步骤</a></li><li>2.6: <a href=#pg-675ad318dc95d5a2edd69400c4712727></a></li></ul><li>3: <a href=#pg-664c42187cbd9876a7d5ae8a17ec02ce>开发指引</a></li><ul><li>3.1: <a href=#pg-b5d18f6a5a5de4c1a4b8632ce9d76df1>API 使用指引</a></li></ul><li>4: <a href=#pg-d2fc2e9c475dda096ccff56f6718d569></a></li><li>5: <a href=#pg-9a2a5aa9bc2d08d259f1ad9a976eb560></a></li><li>6: <a href=#pg-fab69c9d83a9da61b39c006b88f3929a></a></li><li>7: <a href=#pg-d6c47ffbd194dbcf1a4bd38a6989cb38></a></li><li>8: <a href=#pg-268b773d92ea9b8a5d1139d9967931cb></a></li><li>9: <a href=#pg-eb6bff7c19b6b3ec5754d7578215e030></a></li></ul><div class=content></div></div><div class=td-content><h1 id=pg-6e17e09fffc1050f46600282def85180>1 - 简介</h1><div class=lead>Tke stack 简介.</div><p><img src="https://avatars0.githubusercontent.com/u/57258287?s=200&v=4" alt></p><p><img src="https://github.com/tkestack/tke/workflows/build/badge.svg?branch=master" alt="TKEStack Logo"> <img src=https://github.com/tkestack/tke/workflows/build-web/badge.svg alt=build-web> <a href=https://goreportcard.com/report/tkestack.io/tke><img src=https://goreportcard.com/badge/tkestack.io/tke alt="Go Report Card"></a> <a href=https://github.com/tkestack/tke/releases><img src="https://img.shields.io/github/release/tkestack/tke.svg?style=flat-square" alt=Release></a></p><blockquote><p>在线文档地址：<a href=https://tkestack.github.io/web/zh/docs/>https://tkestack.github.io/web/zh/docs/</a></p></blockquote><p><em><strong>TKEStack</strong></em> 是一个开源项目，为在生产环境中部署容器的组织提供一个<strong>统一的容器管理平台</strong>。 <em><strong>TKEStack</strong></em> 可以简化部署和使用 Kubernetes，满足 IT 要求，并增强 DevOps 团队的能力。</p><h2 id=特点>特点</h2><ul><li><strong>统一集群管理</strong><ul><li>提供 Web 控制台和命令行客户端，用于集中管理多个 Kubernetes 集群</li><li>可与现有的身份验证机制集成，包括 LDAP，Active Directory，front proxy 和 public OAuth providers（例如GitHub）</li><li>统一授权管理，不仅在集群管理级别，甚至在Kubernetes资源级别</li><li>多租户支持，包括团队和用户对容器、构建和网络通信的隔离</li></ul></li><li><strong>应用程序工作负载管理</strong><ul><li>提供直观的UI界面，以支持可视化、YAML导入、其他资源创建和编辑方法，使用户无需预先学习所有Kubernetes概念即可运行容器</li><li>抽象的项目级资源容器，以支持跨多个集群的多个名称空间管理和部署应用程序</li></ul></li><li><strong>运维管理</strong><ul><li>集成的系统监控和应用程序监控</li><li>支持对接外部存储，以实现持久化Kubernetes事件和审计日志</li><li>限制，跟踪和管理平台上的开发人员和团队</li></ul></li><li><strong>插件支持和管理</strong><ul><li>Authentication identity provider 插件</li><li>Authorization provider 插件</li><li>事件持久化存储插件</li><li>系统和应用程序日志持久化存储插件</li></ul></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-273a1d3f87830cbffaaf95a64d1ab7e6>2 - 部署</h1><div class=lead>部署架构， 环境要求， 部署步骤</div></div><div class=td-content><h1 id=pg-f6d1bc768009a5736551eb833bad5d9e>2.1 - 产品部署架构</h1><div class=lead>产品部署架构描述</div><h2 id=总体架构>总体架构</h2><p>TKEStack 产品架构如下图所示：</p><p><img src=./images/tkestackhighlevelarchitecture-2x.png alt></p><h2 id=架构说明>架构说明</h2><p>TKEStack 采用了 Kubernetes on Kubernetes 的设计理念。即节点仅运行 Kubelet 进程，其他组件均采用容器化部署，由 Kubernetes 进行管理。</p><p>架构上分为 Global 集群和业务集群。Global 集群运行整个容器服务开源版平台自身所需要的组件，业务集群运行用户业务。在实际的部署过程中，可根据实际情况进行调整。</p><h2 id=模块说明>模块说明</h2><ul><li>Installer: 运行 tke-installer 安装器的节点，用于提供 Web UI 指导用户在 Global 集群部署TKEStacl控制台；</li><li>Global Cluster: 运行的 TKEStack 控制台的 Kubernetes 集群；</li><li>Cluster: 运行业务的 Kubernetes 集群，可以通过 TKEStack 控制台创建或导入；</li><li>Auth: 权限认证组件，提供用户鉴权、权限对接相关功能；</li><li>Gateway: 网关组件，实现集群后台统一入口、统一鉴权相关的功能，并运行控制台的 Web 界面服务；</li><li>Platform: 集群管理组件，提供 Global 集群管理多个业务集群相关功能；</li><li>Business: 业务管理组件，提供平台业务管理相关功能的后台服务；</li><li>Network Controller：网络服务组件，支撑 Galaxy 网络功能；</li><li>Monitor: 监控服务组件，提供监控采集、上报、告警相关服务；</li><li>Notify: 通知功能组件，提供消息通知相关的功能；</li><li>Registry: 镜像服务组件，提供平台镜像仓库服务；</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-772f3961b57805af450afc37610035eb>2.2 - 部署环境要求</h1><div class=lead>部署环境要求</div><h2 id=硬件要求>硬件要求</h2><blockquote><p><strong>特别注意</strong>：</p><ol><li><p>安装的时候，至少需要<strong>一个 Installer 节点</strong>和<strong>一个作为 Global 集群的 master 节点</strong>共<strong>两个节点</strong>。
>
> v1.3.0 之后的版本可直接使用 All-In-One 的安装模式，此时 Installer 节点也可以作为 Global 集群的节点。但注意：此时 Installer 的节点配置要以 Global 集群的节点配置为准，否则 Installer 节点配置太低很容易安装失败。另外该功能还不是很成熟，为避免安装失败，尽量<strong>将 Installer 节点和 Global 节点分开始用</strong></p></li><li><p><strong>Installer 节点</strong>：是单独的用作安装的节点，不能作为 Global 集群的节点使用。因为在安装 Global 集群时，需要多次重启 docker，此时如果 Global 集群里面有 Installer 节点，重启 docker 会中断 Global 集群的安装。该节点需要一台<strong>系统盘 100G</strong> 的机器，系统盘要保证剩余 <strong>50GB 可用的空间</strong>。
>
> <strong>v1.3.0 之后 Installer 节点支持作为 Global 集群的节点使用，但注意此时 Installer 节点配置以 Global 集群的节点为准</strong></p></li><li><p><strong>Global 集群</strong>：至少需要一台 <strong>8核16G内存，100G系统盘</strong>的机器。</p></li><li><p><strong>业务集群</strong>：业务集群是在部署完 Global 集群之后再添加的。</p></li></ol></blockquote><ul><li><strong>最小化部署硬件配置：</strong></li></ul><table><thead><tr><th style=text-align:left><strong>安装/业务集群</strong></th><th style=text-align:left><strong>节点/集群</strong></th><th style=text-align:left><strong>CPU 核数</strong></th><th style=text-align:left><strong>内存</strong></th><th style=text-align:left><strong>系统盘</strong></th><th style=text-align:left><strong>数量</strong></th></tr></thead><tbody><tr><td style=text-align:left>安装</td><td style=text-align:left>Installer 节点</td><td style=text-align:left>1</td><td style=text-align:left>2G</td><td style=text-align:left>100G</td><td style=text-align:left>1</td></tr><tr><td style=text-align:left>TKEStack 控制台</td><td style=text-align:left>Global 集群</td><td style=text-align:left>8</td><td style=text-align:left>16G</td><td style=text-align:left>100G</td><td style=text-align:left>1</td></tr><tr><td style=text-align:left>业务集群</td><td style=text-align:left>Master & ETCD</td><td style=text-align:left>4</td><td style=text-align:left>8G</td><td style=text-align:left>100G</td><td style=text-align:left>1</td></tr><tr><td style=text-align:left>业务集群</td><td style=text-align:left>Node</td><td style=text-align:left>8</td><td style=text-align:left>16G</td><td style=text-align:left>100G</td><td style=text-align:left>3</td></tr></tbody></table><ul><li><strong>推荐硬件配置：</strong></li></ul><table><thead><tr><th style=text-align:left><strong>安装/业务集群</strong></th><th style=text-align:left><strong>节点/集群</strong></th><th style=text-align:left><strong>CPU 核数</strong></th><th style=text-align:left><strong>内存</strong></th><th style=text-align:left><strong>系统盘</strong></th><th style=text-align:left><strong>数量</strong></th></tr></thead><tbody><tr><td style=text-align:left>安装</td><td style=text-align:left>Installer 节点</td><td style=text-align:left>1</td><td style=text-align:left>2G</td><td style=text-align:left>100G</td><td style=text-align:left>1</td></tr><tr><td style=text-align:left>TKEStack 控制台</td><td style=text-align:left>Global 节点</td><td style=text-align:left>8</td><td style=text-align:left>16G</td><td style=text-align:left>100G SSD</td><td style=text-align:left>3</td></tr><tr><td style=text-align:left>业务集群</td><td style=text-align:left>Master & ETCD</td><td style=text-align:left>16</td><td style=text-align:left>32G</td><td style=text-align:left>300G SSD</td><td style=text-align:left>3</td></tr><tr><td style=text-align:left>业务集群</td><td style=text-align:left>Node</td><td style=text-align:left>16</td><td style=text-align:left>32G</td><td style=text-align:left>系统盘：100G 数据盘：300G （/var/lib/docker）</td><td style=text-align:left>>3</td></tr></tbody></table><blockquote><p>注意：上表中的<strong>数据盘</strong>（/var/lib/docker）表示的是 docker 相关信息在主机中存储的位置，即<strong>容器数据盘</strong>，包括 docker 的镜像、容器、日志（如果容器的日志文件所在路径没有挂载 volume，日志文件会被写入容器可写层，落盘到容器数据盘里）等文件。建议给此路径挂盘，避免与系统盘混用，避免因容器、镜像、日志等 docker 相关信息导致磁盘压力过大。</p></blockquote><h2 id=软件要求>软件要求</h2><blockquote><p><strong>注意，以下要求针对集群中的所有节点</strong></p></blockquote><table><thead><tr><th style=text-align:left>需求项</th><th style=text-align:left>具体要求</th><th style=text-align:left>命令参考 （以 CentOS 7.6为例）</th></tr></thead><tbody><tr><td style=text-align:left>操作系统</td><td style=text-align:left>Ubuntu 16.04/18.04 LTS (64-bit)<br>CentOS Linux 7.6 (64-bit) Tencent Linux 2.2</td><td style=text-align:left><code>cat /etc/redhat-release</code></td></tr><tr><td style=text-align:left>kernel 版本</td><td style=text-align:left>>= Kernel 3.10.0-957.10.1.el7.x86_64</td><td style=text-align:left><code>uname -sr</code></td></tr><tr><td style=text-align:left>ssh sudo yum CLI</td><td style=text-align:left>确保 Installer 节点及其容器、<br>Global 集群节点及其容器、<br>业务集群节点及其容器&mldr;之间能够 ssh 互联；<br>确保每个节点都有基础工具</td><td style=text-align:left>1. 确保在添加所有节点时，IP 和密码输入正确。<br>2. 确保每个节点都有 sudo 或 root 权限<br>3. 如果是 CentOS，确保拥有 yum；其他操作系统类似，确保拥有包管理器<br>4. 确保拥有命令行工具</td></tr><tr><td style=text-align:left>Swap</td><td style=text-align:left>关闭。 如果不满足，系统会有一定几率出现 io 飙升，造成 docker 卡死。kubelet 会启动失败<br>(可以设置 kubelet 启动参数 &ndash;fail-swap-on 为 false 关闭 swap 检查)</td><td style=text-align:left><code>sudo swapoff -a</code><br><code>sudo sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab</code><br><code># 注意：如果 /etc/fstab有挂载 swap，必须要注释掉，不然重新开机时又会重新挂载 swap</code></td></tr><tr><td style=text-align:left>防火墙</td><td style=text-align:left>关闭。 或者至少要放通22、80、8080、443、6443、2379、2380、10250-10255、31138 端口</td><td style=text-align:left><code>可通过以下关闭防火墙</code><br><code>systemctl stop firewalld && systemctl disable firewalld</code><br><code>或者通过以下命令放通指定端口，例如只放通80端口</code> <code>firewall-cmd --zone=public --add-port=80/tcp --permanent</code></td></tr><tr><td style=text-align:left>SELinux</td><td style=text-align:left>关闭。 Kubernetes 官方要求，否则 kubelet 挂载目录时可能报错 <code>Permission denied</code></td><td style=text-align:left><code>setenforce 0</code><br><code>sed -i "s/SELINUX=enforcing/SELINUX=disabled/g" /etc/selinux/config</code></td></tr><tr><td style=text-align:left>时区</td><td style=text-align:left>所有服务器时区必须统一，建议设置为 <code>Asia/Shanghai</code></td><td style=text-align:left><code>timedatectl set-timezone Asia/Shanghai</code></td></tr><tr><td style=text-align:left>时间同步</td><td style=text-align:left>ETCD 集群各机器需要时间同步，可以利用 chrony 用于系统时间同步；<br>所有服务器要求时间必须同步，误差不得超过 2 秒</td><td style=text-align:left><code>yum install -y chronyd</code><br><code>systemctl enable chronyd && systemctl start chronyd</code></td></tr><tr><td style=text-align:left>路由检查</td><td style=text-align:left>有些设备可能会默认配置一些路由，这些路由可能与 TKEStack 冲突，建议删除这些路由并做相关配置</td><td style=text-align:left><code>ip link delete docker0</code><br><code>ip link add name docker0 type bridge</code><br><code>ip addr add dev docker0 172.17.0.1/16</code></td></tr><tr><td style=text-align:left>docker 检查</td><td style=text-align:left>有些设备可能会默认安装 docker，该 docker 版本可能与 TKEStack 不一致，<br>建议在安装 TKEStack 之前删除docker</td><td style=text-align:left><code>yum remove docker-ce containerd docker-ce-cli -y</code></td></tr></tbody></table></div><div class=td-content style=page-break-before:always><h1 id=pg-783c8ecc2ba7ee0bcac796c85b13d77a>2.3 - 安装使用 GPU</h1><div class=lead>安装使用 GPU 具体步骤，注意事项</div><h1 id=安装使用步骤>安装使用步骤</h1><h2 id=安装使用步骤-1>安装使用步骤</h2><h3 id=限制条件>限制条件</h3><ul><li>用户在安装使用GPU时，要求集群内必须包含GPU机型节点</li><li>该组件基于 Kubernetes DevicePlugin 实现，只能运行在支持 DevicePlugin 的 kubernetes版本（Kubernetes 1.10 之上的版本）</li><li>GPU-Manager 将每张 GPU 卡视为一个有100个单位的资源：当前仅支持 0-1 的小数张卡，如 20、35、50；以及正整数张卡，如200、500等；不支持类似150、250的资源请求；显存资源是以 256MiB 为最小的一个单位的分配显存</li></ul><h3 id=tkestack-支持的-gpu-类型>TKEStack 支持的 GPU 类型</h3><p>TKEStack目前支持两种GPU类型：</p><ul><li>vGPU：虚拟GPU类型(Virtual GPU)，当选择安装此类型的GPU时，平台会自动安装组件<a href=https://github.com/tkestack/gpu-manager>GPUManager</a>，对应在集群中部署的kubernetes资源对象如下：</li></ul><table><thead><tr><th>kubernetes 对象名称</th><th>类型</th><th>建议预留资源</th><th>所属 Namespaces</th></tr></thead><tbody><tr><td>gpu-manager-daemonset</td><td>DaemonSet</td><td>每节点1核 CPU, 1Gi内存</td><td>kube-system</td></tr><tr><td>gpu-quota-admission</td><td>Deployment</td><td>1核 CPU, 1Gi内存</td><td>kube-system</td></tr></tbody></table><ul><li>pGPU: 物理GPU类型(Physical GPU)，当选择安装此类型的GPU时，平台会自动安装组件<a href=https://github.com/NVIDIA/k8s-device-plugin>Nvidia-k8s-device-plugin</a>，对应的在集群中部署的kubernetes资源对象如下：</li></ul><table><thead><tr><th>kubernetes 对象名称</th><th>类型</th><th>建议预留资源</th><th>所属 Namespaces</th></tr></thead><tbody><tr><td>nvidia-device-plugin-daemonset</td><td>DaemonSet</td><td>每节点1核 CPU, 1Gi内存</td><td>kube-system</td></tr></tbody></table><h3 id=安装步骤>安装步骤</h3><h4 id=安装使用-vgpu>安装使用 vGPU</h4><p>用户在新建独立集群时，勾选GPU选项，在下拉选项中选择 vGPU，如下图所示：</p><p><img src=images/gpu-1.png alt=gpu-1.png></p><p>目标机器部分，勾选GPU选项，平台会自动为节点安装GPU驱动，如下图所示：</p><p><img src=images/gpu-2.png alt=gpu-2.png></p><p>等待新建独立集群处于running状态后，可以通过登陆到集群节点通过<code>kubectl</code>查看在集群<code>kube-system</code>命名空间中部署了<code>gpu-manager</code>和<code>gpu-quota-admission</code>两个pod：</p><pre><code># kubectl get pods -n kube-system | grep gpu
gpu-manager-daemonset-2vvbm              1/1     Running   0          2m13s
gpu-quota-admission-76cfff49b6-vdh42     1/1     Running   0          3m2s
</code></pre><h4 id=创建使用-vgpu-的工作负载>创建使用 vGPU 的工作负载</h4><p>TKEStack创建使用GPU的工作负载支持两种方式：第一种是通过TKEStack前端页面创建，第二种是通过后台命令行的方式创建。</p><p>1、 通过前端控制台创建</p><p>在安装了 GPU-Manager 的集群中，创建工作负载时可以设置GPU限制，如下图所示：</p><blockquote><p>注意：</p><ol><li>卡数只能填写 0.1 到 1 之间的两位小数或者是所有自然数，例如：0、0.3、0.56、0.7、0.9、1、6、34，不支持 1.5、2.7、3.54</li><li>显存只能填写自然数 n，负载使用的显存为 n*256MiB</li></ol></blockquote><p><img src=images/gpu-3.png alt=gpu-3.png></p><p>2、 通过后台命令行创建</p><p>使用 YAML 创建使用 GPU 的工作负载，需要在 YAML 文件中为容器设置 GPU 的使用资源。</p><ul><li>CPU 资源需要在 resource 上填写<code>tencent.com/vcuda-core</code></li><li>显存资源需要在 resource 上填写<code>tencent.com/vcuda-memory</code></li></ul><p>如下所示：创建一个使用 0.3 张卡、5GiB 显存的nginx应用（5GiB = 20*256MB）</p><pre><code>apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx
    imagePullPolicy: IfNotPresent
    resources:
      limits:
        tencent.com/vcuda-core: 30
        tencent.com/vcuda-memory: 20
      requests:
        tencent.com/vcuda-core: 30
        tencent.com/vcuda-memory: 20
</code></pre><pre><code># kubectl create -f nginx.yaml
pod/nginx created
</code></pre><blockquote><p>注意：</p><ul><li>如果pod在创建过程中出现CrashLoopBackOff 的状态，且error log如下所示：</li></ul><pre><code>failed to create containerd task: OCI runtime create failed: container_linux.go:380: starting container process caused: process_linux.go:545: container init caused: Running hook #0:: error running hook: exit status 1, stdout: , stderr: nvidia-container-cli: mount error: open failed: /sys/fs/cgroup/devices/system.slice/containerd.service/kubepods-besteffort-podfd3b355a_665c_4c95_8e7f_61fd2111689f.slice/devices.allow: no such file or directory: unknown
</code></pre><p>需要在GPU主机上手动安装libnvidia-container-tools这个组件，首先需要添加repo源：添加repo源， 添加repo源后执行如下命令：</p><pre><code># yum install libnvidia-container-tools
</code></pre><ul><li>如果pod在创建过程中出现如下error log：</li></ul><pre><code>failed to generate spec: lstat /dev/nvidia-uvm: no such file or directory
</code></pre><p>需要在pod所在的主机上手动mount这个设备文件：</p><pre><code># nvidia-modprobe -u -c=0
</code></pre></blockquote><p>查看创建的应用状态：</p><pre><code># kubectl get pods
NAME    READY   STATUS    RESTARTS   AGE
nginx   1/1     Running   0          3s
</code></pre><p>查看GPU监控数据（需要提前安装socat）：</p><pre><code># yum install socat
</code></pre><pre><code># kubectl port-forward svc/gpu-manager-metric -n kube-system 5678:5678
</code></pre><pre><code># curl http://127.0.0.1:5678/metric
</code></pre><p>结果如下</p><pre><code>Handling connection for 5678
# HELP container_gpu_memory_total gpu memory usage in MiB
# TYPE container_gpu_memory_total gauge
container_gpu_memory_total{container_name=&quot;nginx&quot;,gpu_memory=&quot;gpu0&quot;,namespace=&quot;default&quot;,node=&quot;10.0.0.127&quot;,pod_name=&quot;nginx&quot;} 0
container_gpu_memory_total{container_name=&quot;nginx&quot;,gpu_memory=&quot;total&quot;,namespace=&quot;default&quot;,node=&quot;10.0.0.127&quot;,pod_name=&quot;nginx&quot;} 0
# HELP container_gpu_utilization gpu utilization
# TYPE container_gpu_utilization gauge
container_gpu_utilization{container_name=&quot;nginx&quot;,gpu=&quot;gpu0&quot;,namespace=&quot;default&quot;,node=&quot;10.0.0.127&quot;,pod_name=&quot;nginx&quot;} 0
container_gpu_utilization{container_name=&quot;nginx&quot;,gpu=&quot;total&quot;,namespace=&quot;default&quot;,node=&quot;10.0.0.127&quot;,pod_name=&quot;nginx&quot;} 0
# HELP container_request_gpu_memory request of gpu memory in MiB
# TYPE container_request_gpu_memory gauge
container_request_gpu_memory{container_name=&quot;nginx&quot;,namespace=&quot;default&quot;,node=&quot;10.0.0.127&quot;,pod_name=&quot;nginx&quot;,req_of_gpu_memory=&quot;total&quot;} 5120
# HELP container_request_gpu_utilization request of gpu utilization
# TYPE container_request_gpu_utilization gauge
container_request_gpu_utilization{container_name=&quot;nginx&quot;,namespace=&quot;default&quot;,node=&quot;10.0.0.127&quot;,pod_name=&quot;nginx&quot;,req_of_gpu=&quot;total&quot;} 0.30000001192092896
</code></pre><h4 id=安装使用-pgpu>安装使用 pGPU</h4><p>用户在新建独立集群时，勾选GPU选项，在下拉选项中选择pGPU，如下图所示：</p><p><img src=images/gpu-4.png alt=gpu-4.png></p><p>目标机器部分，勾选GPU选项，平台会自动为节点安装GPU驱动，如下图所示：</p><p><img src=images/gpu-2.png alt=gpu-2.png></p><p>等待新建独立集群处于running状态后，可以通过登陆到集群节点通过<code>kubectl</code>查看到，在集群<code>kube-system</code>命名空间中部署了<code>nvidia-device-plugin</code>pod：</p><pre><code># kubectl get pods -n kube-system | grep nvidia
nvidia-device-plugin-daemonset-frdh2     1/1     Running   0          64s
</code></pre><p>通过查看节点信息可以看到GPU资源和使用情况：</p><pre><code># kubectl describe nodes &lt;nodeIP&gt;
</code></pre><p>显示信息如下：</p><pre><code>Capacity:
  cpu:                8
  ephemeral-storage:  154685884Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             32779608Ki
  nvidia.com/gpu:     1
  pods:               256
Allocatable:
  cpu:                7800m
  ephemeral-storage:  142558510459
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             31653208Ki
  nvidia.com/gpu:     1
  pods:               256
</code></pre><h4 id=创建使用vgpu的工作负载>创建使用vGPU的工作负载</h4><ul><li><p>通过控制台创建方式参考vGPU的创建步骤</p></li><li><p>通过命令行创建</p></li></ul><p>通过如下YAML创建使用1个GPU的工作负载：</p><pre><code>apiVersion: v1
kind: Pod
metadata:
  name: gpu-operator-test
spec:
  restartPolicy: OnFailure
  containers:
    - name: cuda-vector-add
      image: &quot;tkestack/cuda-vector-add:v0.1&quot;
      resources:
        limits:
          nvidia.com/gpu: 1
</code></pre><pre><code># kubectl create -f pod.yaml
pod/gpu-operator-test created
</code></pre><p>查看pod的状态和log：</p><pre><code># kubectl get pods
NAME                READY   STATUS      RESTARTS   AGE
gpu-operator-test   0/1     Completed   0          4m51s
</code></pre><pre><code># kubectl logs gpu-operator-test
[Vector addition of 50000 elements]
Copy input data from the host memory to the CUDA device
CUDA kernel launch with 196 blocks of 256 threads
Copy output data from the CUDA device to the host memory
Test PASSED
Done
</code></pre><p>通过再次查看节点信息可以看到GPU已经被分配使用：</p><pre><code>kubectl describe nodes &lt;nodeIP&gt;
</code></pre><pre><code>Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests     Limits
  --------           --------     ------
  cpu                1137m (14%)  282m (3%)
  memory             644Mi (2%)   1000Mi (3%)
  ephemeral-storage  0 (0%)       0 (0%)
  hugepages-1Gi      0 (0%)       0 (0%)
  hugepages-2Mi      0 (0%)       0 (0%)
  nvidia.com/gpu     1            1
</code></pre><h4 id=添加节点使用gpu>添加节点使用GPU</h4><p>在添加节点上使用GPU资源，需要在创建添加节点时勾选GPU选项，如下图所示：</p><p><img src=images/gpu-5.png alt=gpu-5.png></p></div><div class=td-content style=page-break-before:always><h1 id=pg-51fdfea303f27cb5db555430fe8fe2d5>2.4 - 迁移步骤</h1><div class=lead>TKEStack 具体迁移步骤，注意事项</div><h2 id=容器运行时迁移>容器运行时迁移</h2><p><a href=https://tkestack.github.io/web/zh/blog/2021/09/01/container-runtime-migraion/>TKEStack 集群容器运行时迁移</a></p></div><div class=td-content style=page-break-before:always><h1 id=pg-bc59bbbdb54b32c83e332a5bb22589a2>2.5 - 安装步骤</h1><div class=lead>tke stack 具体安装步骤，注意事项</div><h1 id=安装步骤>安装步骤</h1><h2 id=安装步骤-1>安装步骤</h2><h3 id=1-需求检查>1. 需求检查</h3><p>仔细检查每个节点的硬件和软件需求：<a href=environment-requirement.md>installation requirements</a></p><h3 id=2-installer安装>2. Installer安装</h3><p>为了简化平台安装过程，容器服务开源版基于 tke-installer 安装器提供了一个向导式的图形化安装指引界面。</p><p>在您 Installer 节点的终端，执行如下脚本：</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text># amd64
arch=amd64 version=v1.3.1 &amp;&amp; wget https://tke-release-1251707795.cos.ap-guangzhou.myqcloud.com/tke-installer-linux-$arch-$version.run{,.sha256} &amp;&amp; sha256sum --check --status tke-installer-linux-$arch-$version.run.sha256 &amp;&amp; chmod +x tke-installer-linux-$arch-$version.run &amp;&amp; ./tke-installer-linux-$arch-$version.run

# arm64
arch=arm64 version=v1.3.1 &amp;&amp; wget https://tke-release-1251707795.cos.ap-guangzhou.myqcloud.com/tke-installer-linux-$arch-$version.run{,.sha256} &amp;&amp; sha256sum --check --status tke-installer-linux-$arch-$version.run.sha256 &amp;&amp; chmod +x tke-installer-linux-$arch-$version.run &amp;&amp; ./tke-installer-linux-$arch-$version.run
</code></pre></div><blockquote><p>您可以查看 TKEStack <a href=https://github.com/tkestack/tke/releases>Release</a> 按需选择版本进行安装，建议您安装最新版本。</p><p>tke-installer 约为 7GB，包含安装所需的所有资源。</p></blockquote><p>以上脚本执行完之后，终端会提示访问 <a href=http://%5Btke-installer-IP%5D:8080/index.html%EF%BC%8C%E4%BD%BF%E7%94%A8%E6%9C%AC%E5%9C%B0%E4%B8%BB%E6%9C%BA%E7%9A%84%E6%B5%8F%E8%A7%88%E5%99%A8%E8%AE%BF%E9%97%AE%E8%AF%A5%E5%9C%B0%E5%9D%80%EF%BC%8C%E6%8C%89%E7%85%A7%E6%8C%87%E5%BC%95%E5%BC%80%E5%A7%8B%E5%AE%89%E8%A3%85%E6%8E%A7%E5%88%B6%E5%8F%B0%EF%BC%8C%E5%8F%AF%E5%8F%82%E8%80%83%E4%B8%8B%E9%9D%A2%E7%9A%84%E6%8E%A7%E5%88%B6%E5%8F%B0%E5%AE%89%E8%A3%85%E3%80%82>http://[tke-installer-IP]:8080/index.html，使用本地主机的浏览器访问该地址，按照指引开始安装控制台，可参考下面的控制台安装。</a></p><blockquote><p>注意：这里<code>tke-installer-IP</code>地址默认为<strong>内网地址</strong>，如果本地主机不在集群内网，<code>tke-installer-IP</code>为内网地址所对应的<strong>外网地址</strong>。</p></blockquote><h3 id=3-控制台安装>3. 控制台安装</h3><blockquote><p>注意：控制台是运行在global集群之上，控制台安装就是在安装global集群。</p></blockquote><ol><li>填写 TKEStack 控制台基本配置信息</li></ol><p><img src=../images/step-1.png alt></p><ul><li><strong>用户名</strong>：TKEStack 控制台管理员名称（<strong>例如：admin</strong>）</li><li><strong>密码</strong>：TKEStack 控制台管理员密码</li><li><strong>高可用设置</strong>（按需使用，可直接选择【<strong>不设置</strong>】）<ul><li><strong>TKE提供</strong>：在所有 master 节点额外安装 Keepalived 完成 VIP 的配置与连接</li><li><strong>使用已有</strong>：对接配置好的外部 LB 实例</li><li><strong>不设置</strong>：访问第一台 master 节点 APIServer</li></ul></li><li>填写 TKEStack 控制台集群设置信息</li></ul><p><img src=../images/step-2.png alt></p><ul><li><strong>网卡名称</strong>：集群节点使用的网卡，根据实际环境填写正确的网卡名称，默认为eth0（<strong>建议使用默认值</strong>）</li><li><strong>GPU 类型</strong>：（按需使用，可直接选择【<strong>不设置</strong>】）<ul><li><strong>不使用</strong>：不安装 Nvidia GPU 相关驱动</li><li><strong>Virtual</strong>：平台会自动为集群安装 <a href=../key-features/gpumanager.md>GPUManager</a> 扩展组件</li><li><strong>Physical</strong>：平台会自动为集群安装 <a href=https://github.com/NVIDIA/k8s-device-plugin>Nvidia-k8s-device-plugin</a></li></ul></li><li><strong>容器网络：</strong> 将为集群内容器分配在容器网络地址范围内的 IP 地址，您可以自定义三大私有网段作为容器网络， 根据您选择的集群内服务数量的上限，自动分配适当大小的 CIDR 段用于 Kubernetes service；根据您选择 Pod 数量上限/节点，自动为集群内每台服务器分配一个适当大小的网段用于该主机分配 Pod 的 IP 地址（<strong>建议使用默认值</strong>）<ul><li><strong>CIDR：</strong> 集群内 Sevice、 Pod 等资源所在网段</li><li><strong>Pod数量上限/节点：</strong> 决定分配给每个 Node 的 CIDR 的大小</li><li><strong>Service数量上限/集群</strong>：决定分配给 Sevice 的 CIDR 大小</li></ul></li><li><strong>master 节点：</strong> 输入目标机器信息后单击保存，若保存按钮是灰色，单击网页空白处即可变蓝<ul><li><strong>访问地址：</strong> Master 节点<strong>内网 IP</strong>，请配置<strong>至少 8 Cores & 16G内存</strong> 及以上的机型，<strong>否则会部署失败</strong></li><li><strong>SSH 端口</strong>：请确保目标机器安全组开放 SSH 端口和 ICMP 协议，否则无法远程登录和 PING 服务器（建议使用<strong>22</strong>）</li><li><strong>用户名和密码：</strong> 均为添加的节点的用户名和密码</li><li>可以通过节点下面的【添加机器】蓝色字体增加master节点（<strong>按需添加</strong>）</li></ul></li></ul><p><img src=../images/step-3-2.png alt></p><ul><li><strong>高级设置</strong>（非必须）：可以自定义 Global 集群的 Docker、kube-apiserver、kube-controller-manager、kube-scheduler、kubelet 运行参数</li><li>填写 TKEStack 控制台认证信息。（建议使用<strong>TKE提供</strong>）</li></ul><p><img src=../images/step-3-1.png alt></p><ul><li><strong>认证方式：</strong><ul><li><strong>TKE提供</strong>：使用 TKE 自带的认证方式</li><li><strong>OIDC</strong>：使用 OIDC 认证方式，详见 <a href=https://kubernetes.io/docs/reference/access-authn-authz/authentication/#openid-connect-tokens>OIDC</a></li></ul></li><li>填写 TKEStack 控制台镜像仓库信息。（建议使用<strong>TKE提供</strong>）</li></ul><p><img src=../images/step-4.png alt></p><ul><li><strong>镜像仓库类型：</strong><ul><li><strong>TKE提供</strong>：使用 TKE 自带的镜像仓库</li><li><strong>第三方仓库</strong>：对接配置好的外部镜像仓库，此时，TKEStack 将不会再安装镜像仓库，而是使用您提供的镜像仓库作为默认镜像仓库服务</li></ul></li><li>业务设置</li><li>确认是否开启 TKEStack 控制台业务模块。(<strong>建议开启</strong>)</li><li>确实是否开启平台审计功能，审计模块为平台提供了操作记录,用户可以在平台管理进行查询，需用用户提供ES资源。（<strong>按需使用，可不开启</strong>）</li></ul><p><img src=../images/step-5.png alt></p><ol><li>选择 TKEStack 控制台监控存储类型。（建议使用<strong>TKE提供</strong>）</li></ol><p><img src=../images/step-6.png alt></p><ul><li><strong>监控存储类型</strong>：<ul><li><strong>TKE提供</strong>：使用 TKE 自带的 Influxdb 作为存储</li><li><strong>外部 Influxdb</strong>：对接外部的 Influxdb 作为存储</li><li><strong>外部 ES</strong>：对接外部的 Elasticsearch作为存储</li><li><strong>不使用</strong>：不使用监控</li></ul></li><li>确认是否开启 TKEStack 控制台，选择开启则需要填写控制台域名及证书。（<strong>建议使用默认值</strong>）</li></ul><p><img src=../images/step-7.png alt></p><ul><li><strong>监控存储类型</strong>:<ul><li><strong>自签名证书</strong>：使用 TKE 带有的自签名证书</li><li><strong>指定服务器证书</strong>：填写已备案域名的服务器证书</li></ul></li><li>确认 TKEStack 控制台所有配置是否正确。</li></ul><p><img src=../images/step-8.png alt></p><ol><li>开始安装 TKEStack 控制台，安装成功后界面如下，最下面出现【查看指引】的按钮。</li></ol><p><img src=../images/step-9.png alt></p><ol><li>点击【查看指引】，按照指引，在本地主机上添加域名解析，以访问 TKEStack 控制台。</li></ol><p><img src=../images/step-10.png alt></p><ul><li><p><strong>以Linux/MacOS为例</strong>: 在<code>/etc/hosts</code>文件中加入以下两行域名解析</p><ul><li>【IP】 console.tke.com</li><li>【IP】 registry.tke.com</li></ul><blockquote><p>注意：这里域名的【IP】地址默认为<strong>内网地址</strong>，如果本地主机不在集群内网，域名的IP地址应该填该内网地址所对应的<strong>外网地址</strong>。</p></blockquote></li></ul><h3 id=4-访问控制台>4. 访问控制台</h3><p>在本地主机的浏览器地址输入<code>http://console.tke.com</code>,可访问Global集群的控制台界面，输入控制台安装创建的用户名和密码后即可使用TKEStack。</p><h2 id=安装常见问题>安装常见问题</h2><p>安装失败请首先检查硬件和软件需求：<a href=environment-requirement.md>installation requirements</a></p><p>可参考<a href=../faq/installation/>FAQ installation</a>获得更多帮助。</p></div><div class=td-content style=page-break-before:always><h1 id=pg-675ad318dc95d5a2edd69400c4712727>2.6 -</h1><h1 id=readme>readme</h1><p>Because we can not find resources online with static folder,so use this folder to store image.</p><p>If we fix this issue in the future, then we use static folder rather than this folder.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-664c42187cbd9876a7d5ae8a17ec02ce>3 - 开发指引</h1><div class=lead>开发指引</div></div><div class=td-content><h1 id=pg-b5d18f6a5a5de4c1a4b8632ce9d76df1>3.1 - API 使用指引</h1><div class=lead>API 使用指引</div><h2 id=1-调用方式>1. 调用方式</h2><h3 id=11-创建访问凭证>1.1. 创建访问凭证</h3><p>访问【平台管理】控制台，在左侧找到【组织资源】，选择【访问凭证】，新建一个访问凭证。</p><h3 id=12-访问-api>1.2. 访问 API</h3><p>TKEStack上各种资源的接口均以 Kubernetes 原生 API 的形式提供，所有接口使用统一的前缀: <code>http://console.tke.com:8080/platform</code>，请求中需要将上一步申请的访问凭证以<code>"Authorization: Bearer ${访问凭证}"</code>的形式放入 header。</p><p>以查询集群信息为例，使用的请求如下：</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>curl -H &#34;Authorization: Bearer xxxxxxx&#34; \
&#34;http://console.tke.com:8080/platform/apis/platform.tkestack.io/v1/clusters&#34;
</code></pre></div><h3 id=13-查看特定集群的-namespace>1.3. 查看特定集群的 Namespace</h3><p>查看集群所包含的 Namespace 需要传递 &ldquo;X-TKE-ClusterName: cls-xxx&rdquo; 的 header，cls-xxx 为特定集群 ID</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>curl -H &#34;Authorization: Bearer xxxxxxx&#34; \
-H &#34;X-TKE-ClusterName: cls-xxx&#34; \
&#34;http://console.tke.com:8080/platform/api/v1/namespaces&#34;
</code></pre></div><h2 id=2-通过-api-创建应用>2. 通过 API 创建应用</h2><h3 id=21-非-tapp-应用deploymentstatefulsetdaemonset>2.1. 非 TApp 应用（deployment，statefulset，daemonset）</h3><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>curl &#39;http://console.tke.com:8080/platform/apis/apps/v1/namespaces/命名空间/工作负载类型/工作负载名称&#39; 

-X PATCH

-H &#39;Content-Type:application/strategic-merge-patch+json&#39; 

-H &#39;X-TKE-ClusterName:所属集群&#39;

-H &#39;Authorization: Bearer 访问凭证&#39;

-d &#39;{&#34;spec&#34;:{&#34;template&#34;:{&#34;spec&#34;:{&#34;containers&#34;:[{&#34;name&#34;:&#34;容器名称&#34;,&#34;image&#34;:&#34;容器镜像&#34;}]}}}}&#39;
</code></pre></div><p>工作负载类型： 选择需要更新的工作负载类型（deployment，statefulset， daemonset） 所属集群：填写所要更新容器所属集群。 命名空间：填写所要更新容器所属的命名空间。 工作负载名称：填写所要更新容器的工作负载名称。 容器名称：填写所要更新容器的名称。 访问凭证：填写访问该容器资源的访问凭证，可以在“tkestack-组织资源-访问凭证“中获取该信息（<strong>访问凭证有过期时间，如过期需要重新创建</strong>）。 容器镜像：填写所要更新的Docker镜像</p><h3 id=22-tapp>2.2. TApp</h3><p>TApp 是自研的应用类型，更新镜像需要两步，首先获取当前的容器 spec，调整镜像名后在调用更新接口</p><h4 id=221-获取tapp-spec>2.2.1. 获取tapp spec</h4><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>curl &#39;http://console.tke.com:8080/platform/apis/platform.tkestack.io/v1/clusters/所属集群/tapps?namespace=命名空间&amp;name=工作负载名称&#39;

-X GET

-H &#39;Authorization: Bearer 访问凭证&#39;
</code></pre></div><p>返回值示例：</p><p><code>{"apiVersion":"apps.tkestack.io/v1","kind":"TApp","metadata":{"creationTimestamp":"2020-06-10T13:35:54Z","generation":8,"labels":{"k8s-app":"kevintest","qcloud-app":"kevintest"},"name":"kevintest","namespace":"default","resourceVersion":"13925571","selfLink":"/apis/apps.tkestack.io/v1/namespaces/default/tapps/kevintest","uid":"0269fb69-fa87-42f8-9c3a-e1f96cef40f1"},"spec":{"forceDeletePod":true,"replicas":1,"selector":{"matchLabels":{"k8s-app":"kevintest","qcloud-app":"kevintest"}},"template":{"metadata":{"creationTimestamp":null,"labels":{"k8s-app":"kevintest","qcloud-app":"kevintest","tapp_template_hash_key":"9636164821252331163","tapp_uniq_hash_key":"9518255606018677371"}},"spec":{"containers":[{"image":"mirrors.tencent.com/elsanli/devops-demo:62","imagePullPolicy":"Always","livenessProbe":{"failureThreshold":10,"periodSeconds":10,"successThreshold":1,"tcpSocket":{"port":8888},"timeoutSeconds":2},"name":"test","readinessProbe":{"failureThreshold":10,"periodSeconds":30,"successThreshold":1,"tcpSocket":{"port":8888},"timeoutSeconds":2},"resources":{"limits":{"cpu":"100m","memory":"48Mi"},"requests":{"cpu":"100m","memory":"25Mi"}}}],"restartPolicy":"Always"}},"updateStrategy":{}},"status":{"appStatus":"Running","observedGeneration":7,"readyReplicas":0,"replicas":1,"scaleLabelSelector":"k8s-app=kevintest,qcloud-app=kevintest","statuses":{"0":"Pending"}}}</code></p><h3 id=23-更新-tapp-镜像>2.3. 更新 TApp 镜像</h3><p>从上一步返回值中获取想要更新的整个容器的 spec，替换其中的 image 字段，这样做是为了避免将其他字段覆盖为空</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>curl &#39;&#39;http://console.tke.com:8080/platform/apis/platform.tkestack.io/v1/clusters/所属集群/tapps?namespace=命名空间&amp;name=工作负载名称&#39;

-X PATCH

-H &#39;Content-Type:application/merge-patch+json&#39; 

-H &#39;X-TKE-ClusterName:所属集群&#39;

-H &#39;Authorization: Bearer 访问凭证&#39;

-d &#39;{&#34;spec&#34;:{&#34;template&#34;:{&#34;spec&#34;:{&#34;containers&#34;:[{&#34;name&#34;:&#34;容器名称&#34;,&#34;image&#34;:&#34;容器镜像&#34;,&#34;resources&#34;:{&#34;limits&#34;:{&#34;cpu&#34;:&#34;100m&#34;,&#34;memory&#34;:&#34;48Mi&#34;},&#34;requests&#34;:{&#34;cpu&#34;:&#34;100m&#34;,&#34;memory&#34;:&#34;25Mi&#34;}},&#34;livenessProbe&#34;:{&#34;tcpSocket&#34;:{&#34;port&#34;:8888},&#34;timeoutSeconds&#34;:2,&#34;periodSeconds&#34;:10,&#34;successThreshold&#34;:1,&#34;failureThreshold&#34;:10},&#34;readinessProbe&#34;:{&#34;tcpSocket&#34;:{&#34;port&#34;:8888},&#34;timeoutSeconds&#34;:2,&#34;periodSeconds&#34;:30,&#34;successThreshold&#34;:1,&#34;failureThreshold&#34;:10},&#34;imagePullPolicy&#34;:&#34;Always&#34;}]}},&#34;templates&#34;:null}}
</code></pre></div><p>所属集群：填写所要更新容器所属集群。 命名空间：填写所要更新容器所属的命名空间。 工作负载名称：填写所要更新容器的工作负载名称。 容器名称：填写所要更新容器的名称。 访问凭证：填写访问该容器资源的访问凭证，可以在“tkestack-组织资源-访问凭证“中获取该信息（访问凭证有过期时间，如过期需要重新创建）。 容器镜像：填写所要更新的Docker镜像</p><h2 id=3-通过-api-增删集群节点>3. 通过 API 增删集群节点</h2><p>只能对独立集群的节点进行增删操作，不可操作导入集群。</p><h3 id=31-增加节点>3.1. 增加节点</h3><p>URL: <a href=http://console.tke.com:8080/platform/apis/platform.tkestack.io/v1/machines>http://console.tke.com:8080/platform/apis/platform.tkestack.io/v1/machines</a></p><p>Method: POST</p><p>Headers:</p><ol><li>Content-Type: application/json</li><li>Authorization: Bearer xxx</li></ol><p>按照以下命令的格式，将中文部分替换成实际值，发送请求。请求成功后，会返回被创建的Machine对象。</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>curl -X POST \
&#34;http://console.tke.com:8080/platform/apis/platform.tkestack.io/v1/machines&#34; \
-H &#34;Content-Type: application/json&#34; \
-H &#34;Authorization: Bearer 你的访问凭证&#34; \
-d &#39;
{
    &#34;kind&#34;: &#34;Machine&#34;,
    &#34;apiVersion&#34;: &#34;platform.tkestack.io/v1&#34;,
    &#34;metadata&#34;: {
        &#34;generateName&#34;: &#34;mc-&#34;
    },
    &#34;spec&#34;: {
        &#34;finalizers&#34;: [
            &#34;machine&#34;
        ],
        &#34;tenantID&#34;: &#34;租户ID（联系平台管理员获取）&#34;,
        &#34;clusterName&#34;: &#34;集群ID，可通过页面查看（不是集群名称）&#34;,
        &#34;type&#34;: &#34;Baremetal&#34;,
        &#34;ip&#34;: &#34;节点IP&#34;,
        &#34;port&#34;: 节点SSH端口（int）,
        &#34;username&#34;: &#34;root&#34;,
        &#34;password&#34;: &#34;节点root密码(需经base64编码)&#34;
    }
}&#39;
</code></pre></div><p>password base64编码：</p><p><code>echo -n $PASSWORD | base64</code> 假设password原文为123456，则生成的base64编码为MTIzNDU2</p><blockquote><p>PS: 使用 echo 命令时一定加上 -n 参数</p></blockquote><h3 id=32-查看节点>3.2. 查看节点</h3><p>URL: <a href=http://console.tke.com:8080/platform/apis/platform.tkestack.io/v1/machines/$%7Bmachine.metadata.name%7D>http://console.tke.com:8080/platform/apis/platform.tkestack.io/v1/machines/${machine.metadata.name}</a></p><p>Method: GET</p><p>Headers:</p><ol><li>Authorization: Bearer xxx</li></ol><p>假设平台中有 name 为 mc-brd44nzd 的 Machine 对象：</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>{
  &#34;kind&#34;: &#34;Machine&#34;,
  &#34;apiVersion&#34;: &#34;platform.tkestack.io/v1&#34;,
  &#34;metadata&#34;: {
    &#34;name&#34;: &#34;mc-brd44nzd&#34;,
    &#34;generateName&#34;: &#34;mc-&#34;,
    &#34;selfLink&#34;: &#34;/apis/platform.tkestack.io/v1/machines/mc-brd44nzd&#34;,
    &#34;uid&#34;: &#34;9ef7c08f-c535-4e99-b11d-9f7d02be19f5&#34;,
    &#34;resourceVersion&#34;: &#34;343953553&#34;,
    &#34;creationTimestamp&#34;: &#34;2020-02-27T00:25:02Z&#34;
  },
  &#34;spec&#34;: {
    &#34;finalizers&#34;: [
      &#34;machine&#34;
    ],
    &#34;tenantID&#34;: &#34;default&#34;,
    &#34;clusterName&#34;: &#34;xxxx&#34;,
    &#34;type&#34;: &#34;Baremetal&#34;,
    &#34;ip&#34;: &#34;xxxxxx&#34;,
    &#34;port&#34;: 36000,
    &#34;username&#34;: &#34;root&#34;,
    &#34;password&#34;: &#34;xxxxxx&#34;
  }
}
</code></pre></div><p>则查看该 Machine 部署进度的请求为：</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>curl &#34;http://console.tke.com:8080/platform/apis/platform.tkestack.io/v1/machines/mc-brd44nzd&#34; \
-H &#34;Authorization: Bearer 你的访问凭证&#34;
</code></pre></div><h3 id=33-删除节点>3.3. 删除节点</h3><p>URL: <a href=http://console.tke.com:8080/platform/apis/platform.tkestack.io/v1/machines/$%7Bmachine.metadata.name%7D>http://console.tke.com:8080/platform/apis/platform.tkestack.io/v1/machines/${machine.metadata.name}</a></p><p>Method: DELETE</p><p>Headers:</p><ol><li>Authorization: Bearer xxx</li></ol><p>假设平台中有 name 为 mc-brd44nzd 的 Machine 对象，则删除节点的请求为：</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>curl -X DELETE &#34;http://console.tke.com:8080/platform/apis/platform.tkestack.io/v1/machines/mc-brd44nzd&#34; \
-H &#34;Authorization: Bearer 你的访问凭证&#34;
</code></pre></div><h2 id=4-通过-api-获取业务信息>4. 通过 API 获取业务信息</h2><h3 id=41-查看自身所在业务>4.1. 查看自身所在业务</h3><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>curl &#39;http://console.tke.com:8080/business/apis/business.tkestack.io/v1/portal&#39; \
-X GET \
-H &#34;Authorization: Bearer 访问凭证&#34;
</code></pre></div><h3 id=42-查看特定业务包含的-namespace-信息>4.2. 查看特定业务包含的 Namespace 信息</h3><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>curl &#39;http://console.tke.com:8080/business/apis/business.tkestack.io/v1/namespaces/prj-xxx/namespaces&#39; \
-X GET \
-H &#34;Authorization: Bearer 访问凭证&#34;
prj-xxx 为业务 id
</code></pre></div><h3 id=43-查看特定业务信息>4.3. 查看特定业务信息</h3><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>curl &#39;http://console.tke.com:8080/business/apis/business.tkestack.io/v1/projects/prj-xxx&#39; \
-X GET \
-H &#39;Authorization: Bearer 访问凭证&#39;
prj-xxx为业务id
</code></pre></div></div><div class=td-content style=page-break-before:always><h1 id=pg-d2fc2e9c475dda096ccff56f6718d569>4 -</h1><h1 id=如何构建docker镜像>如何构建Docker镜像</h1><h2 id=说明>说明</h2><p>DockerHub 提供了大量的镜像可用，详情可查看 <a href=https://hub.docker.com/>DockerHub 官网</a>。</p><p>Docker 容器的设计宗旨是让用户在相对独立的环境中运行独立的程序。</p><p>Docker 容器程序在镜像内程序运行结束后会自动退出。如果要令构建的镜像在服务中持续运行，需要在创建服务页面指定自身持续执行的程序，如：业务主程序，main 函数入口等。</p><p>由于企业环境的多样性，并非所有应用都能在 DockerHub 找到对应的镜像来使用。 您可以通过以下教程了解到如何将应用打包成Docker镜像。</p><p>Docker 生成镜像目前有两种方式：</p><ul><li>通过 Dockerfile 自动构建镜像；</li><li>通过容器操作，并执行 Commit 打包生成镜像。</li></ul><h2 id=dockerfile-自动编译生成推荐使用>Dockerfile 自动编译生成（推荐使用）</h2><p>以 Dockerhub 官方提供的 WordPress 为例，<a href=https://github.com/docker-library/wordpress/blob/7d40c4237f01892bb6dbc67d1a82f5b15f807ca1/php5.6/apache/Dockerfile>转到 github 查看详情 >></a></p><p>其 Dockfile 源码如下：</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>FROM php:5.6-apache

# install the PHP extensions we need
RUN apt-get update &amp;&amp; apt-get install -y libpng12-dev libjpeg-dev &amp;&amp; rm -rf /var/lib/apt/lists/* \
    &amp;&amp; docker-php-ext-configure gd --with-png-dir=/usr --with-jpeg-dir=/usr \
    &amp;&amp; docker-php-ext-install gd mysqli opcache

# set recommended PHP.ini settings
# see https://secure.php.net/manual/en/opcache.installation.php
RUN { \
        echo &#39;opcache.memory_consumption=128&#39;; \
        echo &#39;opcache.interned_strings_buffer=8&#39;; \
        echo &#39;opcache.max_accelerated_files=4000&#39;; \
        echo &#39;opcache.revalidate_freq=2&#39;; \
        echo &#39;opcache.fast_shutdown=1&#39;; \
        echo &#39;opcache.enable_cli=1&#39;; \
    } &gt; /usr/local/etc/php/conf.d/opcache-recommended.ini

RUN a2enmod rewrite expires

VOLUME /var/www/html

ENV WORDPRESS_VERSION 4.6.1
ENV WORDPRESS_SHA1 027e065d30a64720624a7404a1820e6c6fff1202

RUN set -x \
    &amp;&amp; curl -o wordpress.tar.gz -fSL &#34;https://wordpress.org/wordpress-${WORDPRESS_VERSION}.tar.gz&#34; \
    &amp;&amp; echo &#34;$WORDPRESS_SHA1 *wordpress.tar.gz&#34; | sha1sum -c - \
# upstream tarballs include ./wordpress/ so this gives us /usr/src/wordpress
    &amp;&amp; tar -xzf wordpress.tar.gz -C /usr/src/ \
    &amp;&amp; rm wordpress.tar.gz \
    &amp;&amp; chown -R www-data:www-data /usr/src/wordpress

COPY docker-entrypoint.sh /usr/local/bin/
RUN ln -s usr/local/bin/docker-entrypoint.sh /entrypoint.sh # backwards compat

# ENTRYPOINT resets CMD
ENTRYPOINT [&#34;docker-entrypoint.sh&#34;]
CMD [&#34;apache2-foreground&#34;]
</code></pre></div><p>通过上述 Dockerfile 文件可以了解到，内置执行了许多的 Linux 命令来安装和部署软件。</p><h2 id=操作步骤>操作步骤</h2><p>在终端创建一个名为worldpress的文件夹，在该文件夹下创建 Dockerfile 文件，文件内容即以上代码。通过 <code>docker build ./</code>命令来构建镜像。</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>[root@VM_1_98_centos ~]# mkdir worldpress
[root@VM_1_98_centos ~]# ls
worldpress
[root@VM_1_98_centos ~]# cd worldpress/
[root@VM_1_98_centos worldpress]# vi Dockerfile
[root@VM_1_98_centos worldpress]# ls
Dockerfile
[root@VM_1_98_centos worldpress]# docker build ./
Sending build context to Docker daemon  3.072kB
Step 1/12 : FROM php:5.6-apache
5.6-apache: Pulling from library/php
5e6ec7f28fb7: Pull complete
cf165947b5b7: Pull complete
7bd37682846d: Pull complete
······
</code></pre></div><p>通过 docker images 命令即可查看到构建完成的镜像。</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>[root@VM_88_88_centos worldpress]# docker images
REPOSITORY                                     TAG                 IMAGE ID            CREATED             SIZE
worldpress                                     latest              9f0b470b5ddb        12 minutes ago      420 MB
docker.io/php                                  5.6-apache          eb8333e24502        5 days ago          389.7 MB
</code></pre></div><p>使用 Dockerfile 来构建镜像有以下建议： 1. 尽量精简，不安装多余的软件包。 2. 尽量选择 Docker 官方提供镜像作为基础版本，减少镜像体积。 3. Dockerfile 开头几行的指令应当固定下来，不建议频繁更改，有效利用缓存。 4. 多条 RUN 命令使用''连接，有利于理解且方便维护。 5. 通过 -t 标记构建镜像，有利于管理新创建的镜像。 6. 不在 Dockerfile 中映射公有端口。 7. Push 前先在本地运行，确保构建的镜像无误。</p><h2 id=执行-commit-实现打包生成镜像>执行 Commit 实现打包生成镜像</h2><p>通过 Dockerfile 可以快速构建镜像，而通过 commit 生成镜像可以解决应用在部署过程中有大量交互内容以及难以通过 Dockerfile 构建的问题。</p><p>通过 commit 构建镜像操作如下： 1. 运行基础镜像容器，并进入console。</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>[root@VM_88_88_centos ~]# docker run -i -t centos
[root@f5f1beda4075 /]#
</code></pre></div><ol><li><p>安装需要的软件，并添加配置。</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>[root@f5f1beda4075 /]# yum update &amp;&amp; yum install  openssh-server
Loaded plugins: fastestmirror, ovl
base                                                                                                                                                                    | 3.6 kB  00:00:00     
extras                                                                                                                                                                  | 3.4 kB  00:00:00     
updates                                                                                                                                                                 | 3.4 kB  00:00:00     
(1/4): base/7/x86_64/group_gz                                                                                                                                           | 155 kB  00:00:00     
(2/4): extras/7/x86_64/primary_db                                                                                                                                       | 166 kB  00:00:00     
(3/4): base/7/x86_64/primary_db                                                                                                                                         | 5.3 MB  00:00:00     
(4/4): updates/7/x86_64/primary_db 
......
......
......
Dependency Installed:
fipscheck.x86_64 0:1.4.1-5.el7              fipscheck-lib.x86_64 0:1.4.1-5.el7              openssh.x86_64 0:6.6.1p1-25.el7_2              tcp_wrappers-libs.x86_64 0:7.6-77.el7             
Complete!
</code></pre></div></li><li><p>配置完成后打开新终端保存该镜像。</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>shell
[root@VM_88_88_centos ~]# docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
f5f1beda4075        centos              &#34;/bin/bash&#34;         8 minutes ago       Up 8 minutes                            hungry_kare
[root@VM_88_88_centos ~]# docker commit f5f1beda4075 test:v1.0      
sha256:65325ffd2af9d574afca917a8ce81cf8a710e6d1067ee611a87087e1aa88e4a4
[root@VM_88_88_centos ~]# 
[root@VM_88_88_centos ~]# docker images
REPOSITORY                                     TAG                 IMAGE ID            CREATED             SIZE
test                                           v1.0                65325ffd2af9        11 seconds ago      307.8 MB
</code></pre></div></li></ol></div><div class=td-content style=page-break-before:always><h1 id=pg-9a2a5aa9bc2d08d259f1ad9a976eb560>5 -</h1><h1 id=编写helloworld程序>编写HelloWorld程序</h1><h2 id=操作场景>操作场景</h2><p>本文档旨在帮助大家了解如何快速创建一个容器集群内的 Hello World 的 Node.js 版的服务。</p><h2 id=前提条件>前提条件</h2><ul><li>已部署 <a href=../../installation/environment-requirement.md>TKEStack 控制台</a>。</li><li>已创建集群。如没有另外创建集群，可以先使用global集群。如要尝试创建新集群，请参见 <a href=../../user-guide/platform-console/cluster-mgmt.md>创建集群</a>。</li></ul><h2 id=操作步骤>操作步骤</h2><h3 id=编写代码制作镜像>编写代码制作镜像</h3><h4 id=编写应用程序>编写应用程序</h4><p>以CentOS 7.6为例</p><ol><li><p>安装node.js，然后依次执行以下命令，创建并进入 hellonode 的文件夹。</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>yum install -y nodejs
mkdir hellonode
cd hellonode/
</code></pre></div></li><li><p>执行以下命令，新建并打开 server.js 文件。</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>vim server.js
</code></pre></div></li><li><p>按 “<strong>i</strong>” 或 “<strong>insert</strong>” 切换至编辑模式，将以下内容输入 server.js。</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-javascript data-lang=javascript><span style=color:#204a87;font-weight:700>var</span> <span style=color:#000>http</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#000>require</span><span style=color:#000;font-weight:700>(</span><span style=color:#4e9a06>&#39;http&#39;</span><span style=color:#000;font-weight:700>);</span>
<span style=color:#204a87;font-weight:700>var</span> <span style=color:#000>handleRequest</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#204a87;font-weight:700>function</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>request</span><span style=color:#000;font-weight:700>,</span> <span style=color:#000>response</span><span style=color:#000;font-weight:700>)</span> <span style=color:#000;font-weight:700>{</span>
<span style=color:#000>console</span><span style=color:#000;font-weight:700>.</span><span style=color:#000>log</span><span style=color:#000;font-weight:700>(</span><span style=color:#4e9a06>&#39;Received request for URL: &#39;</span> <span style=color:#ce5c00;font-weight:700>+</span> <span style=color:#000>request</span><span style=color:#000;font-weight:700>.</span><span style=color:#000>url</span><span style=color:#000;font-weight:700>);</span>
<span style=color:#000>response</span><span style=color:#000;font-weight:700>.</span><span style=color:#000>writeHead</span><span style=color:#000;font-weight:700>(</span><span style=color:#0000cf;font-weight:700>200</span><span style=color:#000;font-weight:700>);</span>
<span style=color:#000>response</span><span style=color:#000;font-weight:700>.</span><span style=color:#000>end</span><span style=color:#000;font-weight:700>(</span><span style=color:#4e9a06>&#39;Hello World!&#39;</span><span style=color:#000;font-weight:700>);</span>
<span style=color:#000;font-weight:700>};</span>
<span style=color:#204a87;font-weight:700>var</span> <span style=color:#000>www</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#000>http</span><span style=color:#000;font-weight:700>.</span><span style=color:#000>createServer</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>handleRequest</span><span style=color:#000;font-weight:700>);</span>
<span style=color:#000>www</span><span style=color:#000;font-weight:700>.</span><span style=color:#000>listen</span><span style=color:#000;font-weight:700>(</span><span style=color:#0000cf;font-weight:700>80</span><span style=color:#000;font-weight:700>);</span>
</code></pre></div><p>按 “<strong>Esc</strong>”，输入 “<strong>:wq</strong>”，保存文件并返回。</p></li><li><p>执行以下命令，执行 server.js 文件。</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>node server.js
</code></pre></div></li><li><p>测试 Hello World 程序，有以下两种办法。 1. 另起一个终端，再次登录节点，执行以下命令。</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>   curl 127.0.0.1:80

   # 终端会输出一下信息
   Hello World!
</code></pre></div><ol><li><p>打开本地主机的浏览器，以<code>IP地址:端口</code>的形式访问，端口为80。 网页出现<code>Hello world!</code>说明 Hello World 程序运行成功。</p><blockquote><p>注意：如果本地主机不在该节点所在的内网，IP地址应该是该节点的外网地址</p></blockquote></li></ol></li></ol><h4 id=创建-docker-镜像>创建 Docker 镜像</h4><ol><li><p>在 hellonode 文件夹下，创建 Dockerfile 文件。</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>[root@VM_1_98_centos hellonode]# vim Dockerfile
</code></pre></div></li><li><p>按 “<strong>i</strong>” 或 “<strong>insert</strong>” 切换至编辑模式，将以下内容输入 Dockerfile 文件。</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>FROM node:4.4
EXPOSE 80
COPY server.js .
CMD node server.js
</code></pre></div><p>按 “<strong>Esc</strong>”，输入 “<strong>:wq</strong>”，保存文件并返回。</p></li><li><p>执行以下命令，构建镜像。</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>docker build -t hello-node:v1 .
</code></pre></div></li><li><p>执行以下命令，查看构建好的 hello-node 镜像。</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>docker images
</code></pre></div><p>显示结果如下，则说明 hello-node 镜像已成功构建，记录其 IMAGE ID。如下图所示：</p><p><img src=../../images/helloworld-3.png alt></p></li></ol><h4 id=上传该镜像到镜像仓库>上传该镜像到镜像仓库</h4><blockquote><ul><li>已在<a href=../../user-guide/platform-console/registry-mgmt/>【组织资源】</a>中的【镜像仓库管理】创建命名空间。</li><li>已在<a href=../../user-guide/platform-console/registry-mgmt/>【组织资源】</a>中的【访问凭证】创建访问凭证。</li></ul></blockquote><p>依次执行以下命令，上传镜像到 qcloud 仓库。</p><div class=highlight><pre style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text>sudo docker login -u tkestack -p 【访问凭证】 default.registry.tke.com
sudo docker tag 【IMAGEID】 default.registry.tke.com/【命名空间】/helloworld:v1
sudo docker push default.registry.tke.com/【命名空间】/helloworld:v1
</code></pre></div><blockquote><ul><li>请将命令中的 【访问凭证】 替换为 已创建的访问凭证。</li><li>请将命令中的 【IMAGEID】 替换为 你自己创建镜像的ID，示例中的ID如上图158204134510。</li><li>请将命令中的 【命名空间】 替换为 已创建的命名空间。</li></ul><p>显示以下结果，则说明镜像上传成功。 <img src=../../images/helloworld-4.png alt></p></blockquote><h4 id=在镜像仓库命名空间中进行确认>在镜像仓库命名空间中进行确认</h4><p><img src=../../images/helloworld-6.png alt></p><h3 id=通过该镜像创建-hello-world-服务>通过该镜像创建 Hello World 服务</h3><ol><li><p>登录 TKEStack 控制台。</p></li><li><p>单击左侧导航栏中【集群管理】，进入“集群管理”页面。</p></li><li><p>单击需要创建服务的集群 ID，进入工作负载 “Deployment” 详情页，选择【新建】。如下图所示：</p><p><img src=../../images/helloworld-5.png alt></p></li><li><p>在“新建Workload”页面，仅输入以下红框内容即可：</p><p><img src=../../images/helloworld-8.png alt></p><p><img src=../../images/helloworld-7.png alt><img src=../../images/helloworld-10.png alt></p><blockquote><p>注意：</p><ol><li>镜像，地址要填全：default.registry.tke.com/【命名空间】/【镜像名】，例如：default.registry.tke.com/test/helloworld</li><li>服务所在集群的安全组需要放通节点网络及容器网络，同时需要放通30000 - 32768端口，否则可能会出现容器服务无法使用问题。</li></ol></blockquote></li><li><p>单击【创建Workload】，完成 Hello World 服务的创建。</p></li></ol><h3 id=访问-hello-world-服务>访问 Hello World 服务</h3><p>可通过以下两种方式访问 Hello World 服务。</p><h4 id=通过主机节点端口访问-hello-world-服务>通过主机节点端口访问 Hello World 服务</h4><ol><li><p>选择【服务】>【Service】，在“Service”管理页面，看到与名为helloworld的Deployment同名的 helloworld Service已经运行，如下图所示：<img src=../../images/helloworld-11.png alt></p></li><li><p>在本地主机的浏览器地址栏输入<code>集群任意节点IP:30000 端口</code>，例如<code>10.0.0.1:30000</code>即可访问服务。如果服务创建成功，访问服务时页面会返回<code>Hello World！</code></p><blockquote><p>注意：如果本地主机在集群内网中，输入节点的内网IP地址即可；如果本地主机不在集群内网中，需要输入节点的外网IP地址</p></blockquote></li></ol><h4 id=通过服务名称访问-hello-world-服务>通过服务名称访问 Hello World 服务</h4><p>集群内的其他服务或容器可以直接通过服务名称访问。</p><p>更多关于Docker 镜像请参见 <a href=docker-image-example.md>如何构建 Docker 镜像</a> 。</p></div><div class=td-content style=page-break-before:always><h1 id=pg-fab69c9d83a9da61b39c006b88f3929a>6 -</h1><h1 id=创建nginx服务>创建Nginx服务</h1><p>本文档旨在帮助大家了解如何快速创建一个容器集群内的 nginx 服务。</p><h2 id=前提条件>前提条件</h2><blockquote><ul><li>已部署 <a href=../../installation/environment-requirement.md>TKEStack 控制台</a>。</li><li>已创建集群。如没有另外创建集群，可以先使用global集群。如要尝试创建新集群，请参见 <a href=../../user-guide/platform-console/cluster-mgmt.md>创建集群</a>。</li></ul></blockquote><h2 id=操作步骤>操作步骤</h2><h3 id=创建-nginx-服务>创建 Nginx 服务</h3><ol><li>登录TKEStack 控制台 。</li></ol><p><img src=../../images/nginx-0.png alt></p><ol><li>单击左侧导航栏中【集群管理】，进入“集群管理”页面，单击需要创建服务的集群 ID。</li></ol><p><img src=../../images/nginx-1.png alt></p><ol><li>进入【工作负载】的【 Deployment 】中，选择【新建】。如下图所示：</li></ol><p><img src=../../images/nginx-2%20%281%29%20%281%29%20%282%29.png alt></p><ol><li>在“新建Workload”页面，只需输入下图中红框的参数即可。</li></ol><p><img src=../../images/nginx-2%20%281%29%20%281%29.png alt></p><p><img src=../../images/nginx-3.png alt></p><p><img src=../../images/nginx-4.png alt></p><blockquote><p>注意：服务所在集群的安全组需要放通节点网络及容器网络，同时需要放通30000 - 32768端口，否则可能会出现容器服务无法使用问题。</p></blockquote><ol><li>单击上图中的【创建Workload】，完成创建。如下图所示：</li></ol><blockquote><p>注意：当运行/期望Pod数量一致时，负载完成创建。</p></blockquote><p><img src=../../images/nginx-5.png alt></p><ol><li>如果在第5步中有创建Service，则可以在【服务】下的【Service】看到与刚刚创建的Deployment同名的Service</li></ol><p><img src=../../images/nginx-6.png alt></p><h3 id=访问-nginx-服务>访问 Nginx 服务</h3><p>可通过以下两种方式访问 nginx 服务。</p><h4 id=通过主机节点端口访问-nginx-服务>通过主机节点端口访问 nginx 服务</h4><p>在本地主机的浏览器地址栏输入<code>集群任意节点IP:30000 端口</code>，例如<code>10.0.0.1:30000</code>即可访问服务。如果服务创建成功，访问服务时直接进入 nginx 服务器的默认欢迎页。如下图所示：</p><blockquote><p>注意：如果本地主机在集群内网中，输入节点的内网IP地址即可；如果本地主机不在集群内网中，需要输入节点的外网IP地址</p></blockquote><p><img src=https://main.qcloudimg.com/raw/37246241fe0abd1d3796c080b1661217.png alt></p><h4 id=通过服务名称访问-nginx-服务>通过服务名称访问 nginx 服务</h4><p>集群内的其他服务或容器可以直接通过服务名称访问。</p></div><div class=td-content style=page-break-before:always><h1 id=pg-d6c47ffbd194dbcf1a4bd38a6989cb38>7 -</h1><h1 id=入门示例>入门示例</h1></div><div class=td-content style=page-break-before:always><h1 id=pg-268b773d92ea9b8a5d1139d9967931cb>8 -</h1><h1 id=快速入门>快速入门</h1><h2 id=教程介绍>教程介绍</h2><p>TKEStack 是一款面向私有化环境的开源容器编排引擎。在本教程中，您将了解如何创建 TKEStack 控制台，并使用控制台创建和管理容器集群，在集群内快速、弹性地部署您的服务。</p><h2 id=操作步骤>操作步骤</h2><h3 id=平台安装>平台安装</h3><p>参考：<a href=../installation/installation-steps.md>installation-procedures</a></p><h3 id=集群>集群</h3><p>平台安装之后，可在【平台管理】控制台的【集群管理】中看到 global 集群。如下图所示：</p><p><img src=../images/cluster%20%282%29%20%282%29%20%289%29.png alt></p><p>TKEStack 还可以另外<strong>新建独立集群</strong>以及<strong>导入已有集群</strong>实现<strong>多集群的管理</strong>。</p><blockquote><p>注意：<strong>新建独立集群</strong>和<strong>导入已有集群</strong>都属于<a href=../installation/installation-architecture.md>TKEStack 架构</a>中的<strong>业务集群</strong>。</p></blockquote><h4 id=新建独立集群>新建独立集群</h4><ol><li>登录 TKEStack，右上角会出现当前登录的用户名，示例为 admin。</li><li>切换至【平台管理】控制台。</li><li>在“集群管理”页面中，单击【新建独立集群】。如下图所示：</li></ol><p><img src=../images/createCluster.png alt></p><ol><li>在“新建独立集群”页面，填写集群的基本信息。新建的集群需满足<a href=../installation/environment-requirement.md>installation requirements</a>的需求，在满足需求之后，TKEStack 的集群添加非常便利。如下图所示,只需填写【集群名称】、【目标机器】、【密码】，其他保持默认即可添加新的集群。</li></ol><blockquote><p>注意：若【保存】按钮是灰色，单击附近空白处即可变蓝</p></blockquote><p><img src=../images/ClusterInfo.png alt></p><ol><li><p>集群名称**：** 支持**中文**，小于 60 字符即可</p></li><li><p>Kubernetes 版本**：** 选择合适的 kubernetes 版本，各版本特性对比请查看 <a href=https://kubernetes.io/docs/home/supported-doc-versions/>Supported Versions of the Kubernetes Documentation</a>。（**建议使用默认值**）</p></li><li><p>运行时组件：根据需求选择使用的运行时组件Docker或者Containerd。</p></li><li><p>网卡名称： 最长 63 个字符，只能包含小写字母、数字及分隔符(' - &lsquo;)，且必须以小写字母开头，数字或小写字母结尾。（<strong>建议使用默认值 eth0</strong>）</p></li><li><p>VIP ：高可用 VIP 地址。（<strong>按需使用</strong>）</p></li><li><p>metrics server: 选择是否使用metrics server。</p></li><li><p>CNI: 根据需求选择使用CNI组件Galaxy或者Cilium。</p></li><li><p>GPU：选择是否安装 GPU 相关依赖。（<strong>按需使用</strong>）</p></li><li><p>pGPU：平台会自动为集群安装 <a href=../key-features/gpumanager.md>GPUManager</a> 扩展组件</p></li><li><p>vGPU：平台会自动为集群安装 <a href=https://github.com/NVIDIA/k8s-device-plugin>Nvidia-k8s-device-plugin</a></p></li><li><p>容器网络 ：将为集群内容器分配在容器网络地址范围内的 IP 地址，您可以自定义三大私有网段作为容器网络， 根据您选择的集群内服务数量的上限，自动分配适当大小的 CIDR 段用于 kubernetes service；根据您选择 Pod 数量上限/节点，自动为集群内每台云服务器分配一个适当大小的网段用于该主机分配 Pod 的 IP 地址。（<strong>建议使用默认值</strong>）</p></li><li><p><strong>CIDR</strong>： 集群内 Sevice、 Pod 等资源所在网段。</p></li><li><p><strong>Pod 数量上限/节点</strong>： 决定分配给每个 Node 的 CIDR 的大小。</p></li><li><p><strong>Service 数量上限/集群</strong> ：决定分配给 Sevice 的 CIDR 大小。</p></li><li><p>目标机器 ：</p></li><li><p><strong>目标机器</strong>：节点的内网地址。（建议: Master&Etcd 节点配置<strong>4 核</strong>及以上的机型）</p></li><li><p><strong>SSH 端口</strong>： 请确保目标机器安全组开放 22 端口和 ICMP 协议，否则无法远程登录和 PING 云服务器。（<strong>建议使用默认值 22</strong>）</p></li><li><p><strong>主机 label</strong>：给主机设置 Label,可用于指定容器调度。（<strong>按需使用</strong>）</p></li><li><p><strong>认证方式</strong>：连接目标机器的方式</p><ul><li><strong>密码认证</strong>：<ul><li><strong>密码</strong>：目标机器密码</li></ul></li><li><strong>密钥认证</strong>：<ul><li><strong>私钥</strong>：目标机器秘钥</li><li><strong>私钥密码</strong>：目标机器私钥密码，可选填</li></ul></li></ul></li><li><p><strong>GPU</strong>： 使用 GPU 机器需提前安装驱动和 runtime。（<strong>按需使用</strong>）</p><blockquote><p>输入以上信息后单击【保存】后还可<strong>继续添加集群的节点</strong></p></blockquote></li><li><p><strong>提交</strong>： 集群信息填写完毕后，【提交】按钮变为可提交状态，单击即可提交。</p></li></ol><h3 id=导入已有集群>导入已有集群</h3><ol><li>登录 TKEStack。</li><li>切换至【平台管理】控制台。</li><li>在“集群管理”页面，单击【导入集群】。如下图所示：</li></ol><p><img src=../images/importCluster-1.png alt></p><ol><li>在“导入集群”页面，填写被导入的集群信息。如下图所示：</li></ol><p><img src=../images/importCluster-2.png alt></p><ol><li>名称： 被导入集群的名称，最长 60 字符</li><li>API Server：</li><li>被导入集群的 API server 的域名或 IP 地址，注意域名不能加上 https://</li><li>端口，此处用的是 https 协议，端口应填 443。</li><li>CertFile： 输入被导入集群的 cert 文件内容</li><li>Token： 输入被导入集群创建时的 token 值</li><li>单击最下方 【提交】 按钮 。</li></ol><h3 id=创建业务>创建业务</h3><blockquote><p>注：业务可以实现跨集群资源的使用</p></blockquote><ol><li>登录 TKEStack。</li><li>在【平台管理】控制台的【业务管理】中，单击 【新建业务】。如下图所示：</li></ol><p><img src=../images/createbusiness.png alt></p><ol><li>在“新建业务”页面，填写业务信息。如下图所示：</li></ol><p><img src=../images/createbusiness.png alt></p><ol><li>业务名称：不能超过 63 个字符，这里以<code>my-business</code>为例</li><li>业务成员： <a href=../user-guide/platform-console/access-mgmt/>【访问管理】</a>中【用户管理】中的用户，这里以<code>admin</code>例，即这该用户可以访问这个业务。</li><li>集群：</li><li>【集群管理】中的集群，这里以<code>gobal</code>集群为例</li><li>【填写资源限制】可以设置当前业务使用该集群的资源上限（可不限制）</li><li>【新增集群】可以添加多个集群，此业务可以使用多个集群的资源（按需添加）</li><li>上级业务：支持多级业务管理，按需选择（可不选）</li></ol><p>8 .单击最下方 【完成】 按钮即可创建业务。</p><h3 id=创建业务下的命名空间>创建业务下的命名空间</h3><ol><li>登录 TKEStack。</li><li>在【平台管理】控制台的【业务管理】中，单击【业务 id】。如下图所示：</li></ol><p><img src=../images/businessid.png alt></p><ol><li>单击【Namespace 列表】。如下图标签 1 所示：</li></ol><blockquote><p>该页面可以更改业务名称、成员、以及业务下集群资源的限制。</p></blockquote><p><img src=../images/businessns%20%281%29.png alt></p><ol><li>单击【新建 Namespace】。如下图所示：</li></ol><p><img src=../images/newns.png alt></p><ol><li>在“新建 Namespace”页面中，填写相关信息。如下图所示：</li></ol><p><img src=../images/my-ns.png alt></p><ol><li>名称：不能超过 63 个字符，这里以<code>new-ns</code>为例</li><li>集群：<code>my-business</code>业务中的集群，这里以<code>global</code>集群为例</li><li>资源限制：这里可以限制当前命名空间下各种资源的使用量，可以不设置。</li></ol><h3 id=创建业务下的-deployment>创建业务下的 Deployment</h3><ol><li>登录 TKEStack，点击【平台管理】选项旁边的切换按钮，可以切换到【业务管理】控制台。</li></ol><blockquote><p>注意：因为当前登录的是 admin 用户，【业务管理】控制台只包含在<a href=quick-starts.md#%E5%88%9B%E5%BB%BA%E4%B8%9A%E5%8A%A1>创建业务</a>中成员包含 admin 的业务，如果切换到【业务管理】控制台没有看见任何业务，请确认【平台管理】中【业务管理】中的相关业务的成员有没有当前用户，如没有，请添加当前用户。</p></blockquote><ol><li>点击左侧导航栏中的【应用管理】，如果当前用户被分配了多个业务，可通过下图中标签 3 的选择框选择合适的业务。</li><li>点击【工作负载】，点击下图标签 4 的【Deployment】，此时进入“Deployment”页面，可通过下图中的标签 5 选择 Deployment 的【命名空间】：</li></ol><p><img src=../images/deployment.png alt></p><ol><li>单击上图标签 6【新建】，进入“新建 Workload ”页面。根据实际需求，设置 Deployment 参数。这里参数很多，其中必填信息已用红框标识：</li></ol><p><img src=../images/createdeployment-1.png alt></p><ol><li>工作负载名：输入自定义名称，这里以<code>my-dep</code>为例</li><li>描述：给工作负载添加描述，可不填</li><li>标签：给工作负载添加标签，通过工作负载名默认生成</li><li>命名空间：根据实际需求进行选择</li><li>类型：选择【Deployment（可扩展的部署 Pod）】</li><li><strong>数据卷（选填）</strong>：为容器提供存储，目前支持临时路径、主机路径、云硬盘数据卷、文件存储 NFS、配置文件、PVC，还需挂载到容器的指定路径中。如需指定容器挂载至指定路径时，单击【添加数据卷】<ul><li><strong>临时目录</strong>：主机上的一个临时目录，生命周期和 Pod 一致</li><li><strong>主机路径</strong>：主机上的真实路径，可以重复使用，不会随 Pod 一起销毁</li><li><strong>NFS 盘</strong>：挂载外部 NFS 到 Pod，用户需要指定相应 NFS 地址，格式：127.0.0.1:/data</li><li><strong>ConfigMap</strong>：用户选择在业务 Namespace 下的<a href=../user-guide/business-console/workload-mgmt/pei-zhi-guan-li/configmap.md>ConfigMap</a></li><li><strong>Secret</strong>：用户选择在业务 namespace 下的<a href=../user-guide/business-console/workload-mgmt/pei-zhi-guan-li/secret.md>Secret</a></li><li><strong>PVC</strong>：用户选择在业务 namespace 下的<a href=../user-guide/business-console/workload-mgmt/cun-chu/pv-he-pvc.md>PVC</a></li></ul></li><li><strong>实例内容器</strong>：根据实际需求，为 Deployment 的一个 Pod 设置一个或多个不同的容器。如下图所示：<ul><li><strong>名称</strong>：自定义，这里以<code>my-container</code>为例</li><li><strong>镜像</strong>：根据实际需求进行选择，这里以<code>nginx</code>为例<ul><li><strong>镜像版本（Tag）</strong>：根据实际需求进行填写，不填默认为<code>latest</code></li><li><strong>CPU/内存限制</strong>：可根据 <a href=https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/>Kubernetes 资源限制</a> 进行设置 CPU 和内存的限制范围，提高业务的健壮性（<strong>建议使用默认值</strong>）</li><li><strong>GPU 限制</strong>：如容器内需要使用 GPU，此处填 GPU 需求</li><li><strong>环境变量</strong>：用于设置容器内的变量，变量名只能包含大小写字母、数字及下划线，并且不能以数字开头<ul><li><strong>新增变量</strong>：自己设定变量键值对</li><li><strong>引用 ConfigMap/Secret</strong>：引用已有键值对</li></ul></li><li><strong>高级设置</strong>：可设置 “<strong>工作目录</strong>”、“<strong>运行命令</strong>”、“<strong>运行参数</strong>”、“<strong>镜像更新策略</strong>”、“<strong>容器健康检查</strong>”和“<strong>特权级</strong>”等参数。这里介绍一下镜像更新策略。<ul><li><p><strong>镜像更新策略</strong>：提供以下 3 种策略，请按需选择</p><p>若不设置镜像拉取策略，当镜像版本为空或 <code>latest</code> 时，使用 Always 策略，否则使用 IfNotPresent 策略</p><ul><li><strong>Always</strong>：总是从远程拉取该镜像</li><li><strong>IfNotPresent</strong>：默认使用本地镜像，若本地无该镜像则远程拉取该镜像</li><li><strong>Never</strong>：只使用本地镜像，若本地没有该镜像将报异常</li></ul></li></ul></li></ul></li></ul></li></ol><p><img src=../images/businessns%20%281%29%20%281%29.png alt></p><p><img src=../images/createdeployment-4.png alt></p><ul><li><strong>实例数量</strong>：根据实际需求选择调节方式，设置实例数量。<ul><li><strong>手动调节</strong>：直接设定实例个数</li><li><strong>自动调节</strong>：根据设定的触发条件自动调节实例个数，目前支持根据 CPU、内存利用率和利用量出入带宽等调节实例个数</li></ul></li><li><strong>显示高级设置</strong></li></ul><p><img src=../images/createdeployment-5.png alt></p><ul><li><p><strong>imagePullSecrets</strong>：镜像拉取密钥，用于拉取用户的私有镜像，使用私有镜像首先需要新建 Secret</p></li><li><p><strong>节点调度策略</strong>：根据配置的调度规则，将 Pod 调度到预期的节点。</p><ul><li><strong>不使用调度策略</strong>：k8s 自动调度</li><li><strong>自定义调度规则</strong>：通过节点的 Label 来实现<ul><li><strong>强制满足条件</strong>：调度期间如果满足亲和性条件则调度到对应 node，如果没有节点满足条件则调度失败。</li><li><strong>尽量满足条件</strong>：调度期间如果满足亲和性条件则调度到对应 node，如果没有节点满足条件则随机调度到任意节点。</li></ul></li></ul></li><li><p><strong>注释（Annotations）</strong>：给 deployment 添加相应 Annotation，如用户信息等</p></li><li><p><strong>网络模式</strong>：选择 Pod 网络模式</p><ul><li><strong>OverLay（虚拟网络）</strong>：基于 IPIP 和 Host Gateway 的 Overlay 网络方案</li><li><strong>FloatingIP（浮动 IP）</strong>：支持容器、物理机和虚拟机在同一个扁平面中直接通过 IP 进行通信的 Underlay 网络方案。提供了 IP 漂移能力，支持 Pod 重启或迁移时 IP 不变</li><li><strong>NAT（端口映射</strong>）：Kubernetes 原生 NAT 网络方案</li><li><strong>Host（主机网络）</strong>：Kubernetes 原生 Host 网络方案</li></ul></li><li><p><strong>创建 Service（可选）</strong>：</p></li><li><p><strong>Service</strong>：勾选【启用】按钮，配置负载端口访问</p><blockquote><p>注意：如果不勾选【启用】则不会创建 Service</p></blockquote></li><li><p><strong>服务访问方式</strong>：选择是【仅在集群内部访问】该负载还是集群外部通过【主机端口访问】该负载</p><ul><li><strong>仅在集群内访问</strong>：使用 Service 的 ClusterIP 模式，自动分配 Service 网段中的 IP，用于集群内访问。数据库类等服务如 MySQL 可以选择集群内访问，以保证服务网络隔离</li><li><strong>主机端口访问</strong>：提供一个主机端口映射到容器的访问方式，支持 TCP、UDP、Ingress。可用于业务定制上层 LB 转发到 Node</li><li><strong>Headless Service</strong>：不创建用于集群内访问的 ClusterIP，访问 Service 名称时返回后端 Pods IP 地址，用于适配自有的服务发现机制。解析域名时返回相应 Pod IP 而不是 Cluster IP</li></ul></li><li><p><strong>端口映射</strong>：输入负载要暴露的端口并指定通信协议类型（<strong>容器和服务端口建议都使用 80</strong>）</p></li><li><p><strong>Session Affinity:</strong> 点击【显示高级设置】出现，会话保持，设置会话保持后，会根据请求 IP 把请求转发给这个 IP 之前访问过的 Pod。默认 None，按需使用</p></li><li><p>单击【创建 Workload】，完成创建。</p></li></ul><p>​ 当“运行/期望 Pod 数量”相等时，即表示 Deployment 下的所有 Pod 已创建完成。</p><ul><li>如果在第 5 步中有创建 Service，则可以再【服务】下的【Service】看到与刚刚创建的 Deployment 同名的 Service</li></ul><h3 id=删除资源>删除资源</h3><p>在本节中，启动了<code>my-business</code>业务下的 Deployment 和 Service 两种资源，此步骤介绍如何清除所有资源。</p><h4 id=删除-deployment>删除 Deployment</h4><ol><li>登录 TKEStack，切换到【业务管理】控制台，选择左侧导航栏中的【应用管理】。</li><li>展开【工作负载】下拉项，进入 “Deployment” 管理页面，选择需要删除【Deployment】的业务下相应的【命名空间】，点击要删除的 Deployment 最右边的【更多】，点击【删除】。如下图所示：</li><li>在弹出框中单击【确定】，即可删除 Deployment。</li></ol><h4 id=删除-service>删除 Service</h4><ol><li>登录 TKEStack，切换到【业务管理】控制台，选择左侧导航栏中的【应用管理】。</li><li>展开【服务】下拉项，进入 “Service” 管理页面，选择需要删除【Service】的业务下相应的【命名空间】，点击要删除的 Service 最右边的【删除】。如下图所示：</li><li>在弹出框中单击【确定】，即可删除 Service。</li></ol></div><div class=td-content style=page-break-before:always><h1 id=pg-eb6bff7c19b6b3ec5754d7578215e030>9 -</h1><h1 id=快速入门>快速入门</h1></div></main></div></div><footer class="bg-dark py-5 row d-print-none"><div class="container-fluid mx-sm-5"><div class=row><div class="col-6 col-sm-4 text-xs-center order-sm-2"></div><div class="col-6 col-sm-4 text-right text-xs-center order-sm-3"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub><a class=text-white target=_blank rel=noopener href=https://github.com/tkestack/tke aria-label=GitHub><i class="fab fa-github"></i></a></li></ul></div><div class="col-12 col-sm-4 text-center py-2 order-sm-2"><small class=text-white>&copy; 2021 The TKEStack Authors All Rights Reserved</small></div></div></div></footer></div><script src=https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js integrity=sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js integrity=sha384-+YQ4JLhjyBLPDQt//I+STsc9iw4uQqACwlvpslubQzn4u2UU2UFM80nGisd026JF crossorigin=anonymous></script><script src=/web/js/main.min.1911ee3ae98d7d6df3807cd00d8e31ae7d1c08ee0f0bb587529b0483da4e5464.js integrity="sha256-GRHuOumNfW3zgHzQDY4xrn0cCO4PC7WHUpsEg9pOVGQ=" crossorigin=anonymous></script></body></html>