<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Tkestack – TKEStack</title><link>/web/zh/</link><description>Recent content in TKEStack on Tkestack</description><generator>Hugo -- gohugo.io</generator><atom:link href="/web/zh/index.xml" rel="self" type="application/rss+xml"/><item><title>Blog: TKEStack 容器混合云能力介绍（2）：打破网络边界</title><link>/web/zh/blog/2021/12/20/hybrid-cloud-introduction-2/</link><pubDate>Mon, 20 Dec 2021 00:00:00 +0000</pubDate><guid>/web/zh/blog/2021/12/20/hybrid-cloud-introduction-2/</guid><description>
&lt;p>&lt;strong>Author&lt;/strong>: LeoRyu&lt;/p>
&lt;p>&lt;em>TKEStack 提供了多集群管理能力，其中导入集群功能通过推送模式由 TKEStack 管控集群（global cluster）直连第三方集群的 api-server 进而统一纳管部署在 IDC，公有云或边缘的第三方集群。 但在实际生产环境中， 管控集群和第三方集群之间的直连往往会出现很多阻碍：或是不在同一个二层网络下，或是第三方集群在防火墙/NAT之后，或是第三方集群在网络策略上不允许有入站网络传输，在这些场景下, TKEStack难以直连第三方集群 api-server, 导入集群的能力无法发挥。针对这一问题本文将介绍 TKEStack 如何借助腾讯云原生分布式云中心注册集群的功能打破网络边界的限制，将网络环境相对隔离的集群纳入到 TKEStack 的管控面，进行统一管控。&lt;/em>&lt;/p>
&lt;h2 id="tkestack-的导入集群功能">TKEStack 的导入集群功能&lt;/h2>
&lt;p>开源版 TKEStack 的集群管理中&lt;sup>[1]&lt;/sup>存在两种集群的概念，一种是&lt;code>独立集群&lt;/code>，另一种是&lt;code>导入集群&lt;/code>。&lt;/p>
&lt;p>其中&lt;code>独立集群&lt;/code>需要用户提供可被 TKEStack 访问的 Linux 机器的访问凭证，TKEStack 将以用户提供的机器作为基础设施，从 0 搭建可被 TKEStack 管控的 K8s 集群。&lt;/p>
&lt;img alt="独立集群" width="100%" src="baremetal-cluster.png">
&lt;p>&lt;code>导入集群&lt;/code>则是将用户的现存集群纳入到 TKEStack 的管控之下，但需要此集群可以被 TKEStack 访问到（无需被导入集群可访问 TKEStack），用户在满足此条件前提下可提供被导入集群的访问凭证，便可将集群纳入到 TKEStack 管控视野内。&lt;/p>
&lt;img alt="导入集群" width="100%" src="import-cluster.png">
&lt;p>但是在现实生产环境中，被导入集群有极大的可能性处于外网无法访问的网络环境中，此时我们可以借助腾讯云的分布式云中心来打通 TKEStack 与被导入集群间的网络边界限制。&lt;/p>
&lt;h2 id="打破网络边界">打破网络边界&lt;/h2>
&lt;p>云原生分布式云中心（Tencent Kubernetes Engine Distributed Cloud Center，TDCC）&lt;sup>[2]&lt;/sup> 是腾讯面向多云多集群场景的应用管理平台，支持用户将云原生化的应用扩展到分布式云，打通公有云、私有云、边缘云的界限，将各种成熟的集群、网络、存储、微服务、运维等公有云产品和服务交付至更接近用户和数据的位置，确保不同云基础设施下拥有一致的控制平面，并且提供可靠性保证和安全合规保证，满足企业用户的多云管理、应用治理、高可用容灾等场景诉求。&lt;/p>
&lt;p>下面笔者将演示在家庭网络环境下（可访问公网）使用 kind&lt;sup>[3]&lt;/sup> 创建一个 K8s 集群，并借助分布式云中心，将其导入一个私有云网络环境下（可访问公网）的 TKEStack。由于 TKEStack 在 v1.8 release 时云原生分布式云中心还未上线，这里需要我们使用 daily build 版本进行体验，该功能的正式发布则需要等到稍晚些 TKEStack v1.9.0 发布，daily build 版本下载可参考以下命令：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#000">version&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>310e18e0d696ee0aa57dfe38655b99726eab9f5c &lt;span style="color:#ce5c00;font-weight:bold">&amp;amp;&amp;amp;&lt;/span> wget https://tke-release-1251707795.cos.ap-guangzhou.myqcloud.com/tke-installer-linux-amd64-&lt;span style="color:#000">$version&lt;/span>.run&lt;span style="color:#ce5c00;font-weight:bold">{&lt;/span>,.sha256&lt;span style="color:#ce5c00;font-weight:bold">}&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">&amp;amp;&amp;amp;&lt;/span> sha256sum --check --status tke-installer-linux-amd64-&lt;span style="color:#000">$version&lt;/span>.run.sha256 &lt;span style="color:#ce5c00;font-weight:bold">&amp;amp;&amp;amp;&lt;/span> chmod +x tke-installer-linux-amd64-&lt;span style="color:#000">$version&lt;/span>.run &lt;span style="color:#ce5c00;font-weight:bold">&amp;amp;&amp;amp;&lt;/span> ./tke-installer-linux-amd64-&lt;span style="color:#000">$version&lt;/span>.run
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="创建-kind-集群">创建 kind 集群&lt;/h3>
&lt;p>这里笔者在自己的虚拟机上使用 kind 创建一个集群，首先是安装 kind：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.11.1/kind-linux-amd64
chmod +x ./kind
mv kind /usr/bin/
&lt;/code>&lt;/pre>&lt;/div>&lt;p>然后我们执行 kind 的创建集群命令：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">kind create cluster
&lt;/code>&lt;/pre>&lt;/div>&lt;p>如果不出意外我们将在等待一段时间后得到以下结果：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">Creating cluster &lt;span style="color:#4e9a06">&amp;#34;kind&amp;#34;&lt;/span> ...
✓ Ensuring node image &lt;span style="color:#ce5c00;font-weight:bold">(&lt;/span>kindest/node:v1.21.1&lt;span style="color:#ce5c00;font-weight:bold">)&lt;/span> 🖼
✓ Preparing nodes 📦
✓ Writing configuration 📜
✓ Starting control-plane 🕹️
✓ Installing CNI 🔌
✓ Installing StorageClass 💾
Set kubectl context to &lt;span style="color:#4e9a06">&amp;#34;kind-kind&amp;#34;&lt;/span>
You can now use your cluster with:
kubectl cluster-info --context kind-kind
Not sure what to &lt;span style="color:#204a87;font-weight:bold">do&lt;/span> next? 😅 Check out https://kind.sigs.k8s.io/docs/user/quick-start/
&lt;/code>&lt;/pre>&lt;/div>&lt;p>下面可以使用 kubectl 来确认一下集群是否在正常运行，这里我们就完成了 kind 集群的创建工作。如果你的机器上没有 kubectl 可以参考&lt;a href="https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/">Install and Set Up kubectl on Linux
&lt;/a>进行安装。&lt;/p>
&lt;h3 id="注册集群到分布式云中心">注册集群到分布式云中心&lt;/h3>
&lt;p>访问腾讯云的&lt;a href="https://console.cloud.tencent.com/tdcc/cluster">分布式云中心主页&lt;/a>，选择注册集群按钮。&lt;/p>
&lt;img alt="注册集群1" width="100%" src="register-cluster-1.png">
&lt;p>这里由于我们是通过 kind 创建的集群并非 TKE，所以注意选择非 TKE 集群。&lt;/p>
&lt;img alt="注册集群2" width="100%" src="register-cluster-2.png">
&lt;p>注册集群创建成功后改集群将处于等待注册的状态，点击查看注册命令。&lt;/p>
&lt;img alt="注册集群3" width="100%" src="register-cluster-3.png">
&lt;p>由于我们的 kind 集群无法无法通过内外与分布式云中心通信，注意选择外网访问。&lt;/p>
&lt;img alt="注册集群4" width="100%" src="register-cluster-4.png">
&lt;p>根据提示将&lt;code>agent.yaml&lt;/code>下载下来然后通过 kubectl 部署到 kind 集群：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">kubectl apply -f agent.yaml
&lt;/code>&lt;/pre>&lt;/div>&lt;p>如果顺利我们将会得到以下反馈：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">namespace/clusternet-system created
serviceaccount/clusternet-agent created
serviceaccount/clusternet-app-deployer created
deployment.apps/clusternet-agent created
clusterrole.rbac.authorization.k8s.io/clusternet:app:deployer created
clusterrolebinding.rbac.authorization.k8s.io/clusternet:app:deployer created
secret/clusternet-agent-cluster-registration created
&lt;/code>&lt;/pre>&lt;/div>&lt;p>此时可以通过下面的命令确认下 agent 相关 pod 是否正常工作：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">kubectl get pod -n clusternet-system
&lt;/code>&lt;/pre>&lt;/div>&lt;p>如果正常我们应当会得到类似下面的反馈：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">NAMESPACE NAME READY STATUS RESTARTS AGE
clusternet-system clusternet-agent-6754cc97bb-dk6r4 1/1 Running &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> 8s
clusternet-system clusternet-agent-6754cc97bb-sbpzg 1/1 Running &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> 8s
clusternet-system clusternet-agent-6754cc97bb-zfblp 1/1 Running &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> 8s
&lt;/code>&lt;/pre>&lt;/div>&lt;p>再检查分布式云中心首页我们将发现 kind 集群已经成功注册了进来。&lt;/p>
&lt;h3 id="导入集群到-tkestack">导入集群到 TKEStack&lt;/h3>
&lt;p>下面我们将把 kind 集群导入到 TKEStack 中，首先从分布式云中心将集群的访问凭证下载下来。&lt;/p>
&lt;img alt="注册集群5" width="100%" src="register-cluster-5.png">
&lt;img alt="注册集群6" width="100%" src="register-cluster-6.png">
&lt;p>然后使用此凭证便可将 kind 集群导入到 TKEStack 中。&lt;/p>
&lt;img alt="注册集群7" width="100%" src="register-cluster-7.png">
&lt;img alt="注册集群8" width="100%" src="register-cluster-8.png">
&lt;img alt="注册集群9" width="100%" src="register-cluster-9.png">
&lt;h2 id="原理">原理&lt;/h2>
&lt;p>腾讯云分布式云中心的核心功能由 Clusternet&lt;sup>[4]&lt;/sup> 提供，该项目已经开源，可以在 &lt;a href="https://github.com/clusternet/clusternet">https://github.com/clusternet/clusternet&lt;/a> 仓库下查看代码。&lt;/p>
&lt;p>Clusternet 的核心能力通过&lt;code>clusternet-hub&lt;/code>和&lt;code>clusternet-agent&lt;/code>两个组件实现，&lt;code>clusternet-hub&lt;/code>的角色类似一个电插板，以 aggregated apiserver&lt;sup>[5]&lt;/sup> 形式部署在父集群中等待着子集群被接入进来；&lt;code>clusternet-agent&lt;/code>则在子集群中充当一个派驻信使的角色，一方面将子集群的信息上报给&lt;code>clusternet-hub&lt;/code>以进行观测，另一方面将从&lt;code>clusternet-hub&lt;/code>传送来的指令下发给子集群以进行控制。鉴权模式上 Clusternet 复用了子集群的鉴权能力，通过 K8s 的 user impersonation&lt;sup>[6]&lt;/sup> 能力将认证信息发送到&lt;code>clusternet-agent&lt;/code>模拟对应用户进行操作控制。&lt;/p>
&lt;img alt="clusternet架构" width="100%" src="clusternet-arch.png">
&lt;h2 id="加入我们">加入我们&lt;/h2>
&lt;p>在大家的共同努力下 TKEStack 已经演进到 v1.8.x 版本，其中包括了 containerd 支持、cilium 支持、集群应用定义等诸多新功能，欢迎大家到 &lt;a href="https://github.com/tkestack/tke/releases">https://github.com/tkestack/tke/releases&lt;/a> 下载体验。同时 v1.9.0 版本的开发工作正在主分支上火热进行中，v1.9.0 版本中除了本文介绍的支持导入分布式云中心集群外，我们会全面升级 TKEStack 的各种依赖，包括 golang 版本、CI 工具版本以及 K8s api 版本等，此外我们还将在 TKEStack 的轻量化减负上做出努力，包括移除 TKE 发行版&lt;sup>[7]&lt;/sup>以外的集群版本，删减不常用的 addon 组件等。当下的 TKEStack 正是需要你加入的时候，欢迎大家到项目仓库 &lt;a href="https://github.com/tkestack/tke">https://github.com/tkestack/tke&lt;/a> 贡献一份力量！&lt;/p>
&lt;h2 id="参考资料">参考资料&lt;/h2>
&lt;p>[1] TKEStack 集群管理 [https://tkestack.github.io/docs/user-guide/platform-console/cluster-mgmt.html]&lt;/p>
&lt;p>[2] 腾讯云原生分布式云中心 [https://cloud.tencent.com/document/product/1517/63246]&lt;/p>
&lt;p>[3] Kind, running local Kubernetes clusters using Docker [https://kind.sigs.k8s.io/]&lt;/p>
&lt;p>[4] Clusternet [https://github.com/clusternet/clusternet]&lt;/p>
&lt;p>[5] Kubernetes API Aggregation Layer [https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/apiserver-aggregation/]&lt;/p>
&lt;p>[6] User impersonation [https://kubernetes.io/docs/reference/access-authn-authz/authentication/#user-impersonation]&lt;/p>
&lt;p>[7] TKE Kubernetes Distro [https://github.com/tkestack/tke-k8s-distro]&lt;/p></description></item><item><title>Blog: TKEStack 中的认证与鉴权</title><link>/web/zh/blog/2021/12/18/tkestack-auth/</link><pubDate>Sat, 18 Dec 2021 00:00:00 +0000</pubDate><guid>/web/zh/blog/2021/12/18/tkestack-auth/</guid><description>
&lt;p>&lt;strong>Author&lt;/strong>: LeoRyu&lt;/p>
&lt;p>&lt;em>认证鉴权对于 K8s 而言可以说是最为复杂、灵活和关键的部分，本文将介绍 TKEStack 中认证鉴权机制是如何运作的。&lt;/em>&lt;/p>
&lt;h2 id="开始之前">开始之前&lt;/h2>
&lt;p>由于认证鉴权涉及的相关知识很多，为了避免读者在下面探究 TKEStack 认证鉴权机制时查处相关名词知识，在开始之前先介绍一些本文涉及到的知识概念。&lt;/p>
&lt;h3 id="k8s-中的一些身份认证方式">K8s 中的一些身份认证方式&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>X509 客户证书。通过给 API 服务器传递 &lt;code>--client-ca-file=SOMEFILE&lt;/code> 选项，就可以启动客户端证书身份认证。 所引用的文件必须包含一个或者多个证书机构，用来验证向 API 服务器提供的客户端证书。 如果提供了客户端证书并且证书被验证通过，则 subject 中的公共名称（Common Name）就被 作为请求的用户名。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>静态令牌文件。当 API 服务器的命令行设置了 &lt;code>--token-auth-file=SOMEFILE&lt;/code> 选项时，会从文件中 读取持有者令牌。目前，令牌会长期有效，并且在不重启 API 服务器的情况下 无法更改令牌列表。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>服务账号令牌。服务账号（Service Account）是一种自动被启用的用户认证机制，使用经过签名的 持有者令牌来验证请求。服务账号通常由 API 服务器自动创建并通过 ServiceAccount 准入控制器 关联到集群中运行的 Pod 上。 持有者令牌会挂载到 Pod 中可预知的位置，允许集群内进程与 API 服务器通信。 服务账号也可以使用 Pod 规约的 serviceAccountName 字段显式地关联到 Pod 上。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>OpenID Connect（OIDC）令牌。OpenID Connect 是一种 OAuth2 认证方式， 被某些 OAuth2 提供者支持，例如 Azure 活动目录、Salesforce 和 Google。 协议对 OAuth2 的主要扩充体现在有一个附加字段会和访问令牌一起返回， 这一字段称作 ID Token（ID 令牌）。详情可参考 &lt;a href="https://openid.net/connect/">https://openid.net/connect/&lt;/a> 。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>更多认证相关信息可参考 &lt;a href="https://kubernetes.io/zh/docs/reference/access-authn-authz/authentication/">用户认证&lt;/a>[1]。&lt;/p>
&lt;h3 id="k8s-中的一些鉴权方式">K8s 中的一些鉴权方式&lt;/h3>
&lt;ul>
&lt;li>Node。一个专用鉴权组件，根据调度到 kubelet 上运行的 Pod 为 kubelet 授予权限。&lt;/li>
&lt;li>ABAC。基于属性的访问控制（ABAC）定义了一种访问控制范型，通过使用将属性组合 在一起的策略，将访问权限授予用户。策略可以使用任何类型的属性（用户属性、资源属性、 对象，环境属性等）。&lt;/li>
&lt;li>RBAC。基于角色的访问控制（RBAC）是一种基于企业内个人用户的角色来管理对 计算机或网络资源的访问的方法。在此上下文中，权限是单个用户执行特定任务的能力， 例如查看、创建或修改文件。&lt;/li>
&lt;li>Webhook。WebHook 是一个 HTTP 回调：发生某些事情时调用的 HTTP POST； 通过 HTTP POST 进行简单的事件通知。实现 WebHook 的 Web 应用程序会在发生某些事情时 将消息发布到 URL。&lt;/li>
&lt;li>AlwaysAllow。允许所有请求。仅在你不需要 API 请求 的鉴权时才使用。&lt;/li>
&lt;li>AlwaysDeny。阻止所有请求。仅用于测试。&lt;/li>
&lt;/ul>
&lt;p>更多认证相关信息可参考 &lt;a href="https://kubernetes.io/zh/docs/reference/access-authn-authz/authorization/">鉴权概述&lt;/a>[2]。&lt;/p>
&lt;h3 id="casbin">Casbin&lt;/h3>
&lt;p>Casbin 是一款轻量级的开源访问控制框架，支持 PERM 模式（Policy，Effect，Request，Matchers），相关概念如下：&lt;/p>
&lt;ul>
&lt;li>Request：定义了请求的元组对象，至少包含访问实体（sub）、访问的资源（obj）和行为（Action），例如：r={sub, obj,act}。&lt;/li>
&lt;li>Policy：定义了鉴权规则各字段的名称和顺序，至少包含访问实体（sub）、访问的资源（obj）和行为（Action），例如：p={sub, obj, act}。&lt;/li>
&lt;li>Matchers：定义了 Request 和 Policy 的匹配规则。&lt;/li>
&lt;li>Effect：用于对所有 Matchers 匹配后的结果，再进行一次逻辑组合判断（例如：e = some(where (p.eft == allow)) &amp;amp;&amp;amp; !some(where (p.eft == deny))，这个例子组合的逻辑含义是：如果有匹配出结果为 alllow 的策略，并且没有匹配出结果为 deny 的策略，则结果为真，如果有任何deny，都为假）。&lt;/li>
&lt;/ul>
&lt;p>关于本项目详细信息可以参考 &lt;a href="https://casbin.org/docs/zh-CN/overview">Casbin 概述&lt;/a>[3]。&lt;/p>
&lt;h2 id="两种认证鉴权场景">两种认证鉴权场景&lt;/h2>
&lt;p>TKEStack 扩展 K8s API 的方式是通过 aggregated apiserver[4] 实现的，这种方式与 CRD 的方式不同，每一个扩展组件都可以被视为一个独立的 APIServer，这使得 TKEStack 的认证鉴权相较之下更加灵活，但也更加复杂。为了更加方便和清晰地展示认证鉴权的流程，这里我们分为两种场景分别展开：第一种是用户通过浏览器由 tke-gateway 入口访问各个组件的资源；第二种是用户通过 kubectl 由 kube-apiserver 入口访问各个组件的资源。&lt;/p>
&lt;h2 id="由浏览器发起的访问">由浏览器发起的访问&lt;/h2>
&lt;h3 id="认证">认证&lt;/h3>
&lt;p>用户通过浏览器登陆访问的用户信息并不是 K8s 集群可以识别的用户，无法由集群本身进行认证流程，需要外部的 OIDC provider 进行认证。在 TKEStack 中承担此工作的是 tke-auth 组件，tke-auth 中是通过 &lt;a href="https://github.com/dexidp/dex">dex&lt;/a> 实现的 OIDC 服务。&lt;/p>
&lt;p>在由浏览器发起的访问场景下，认证流程的链路大致分为两步骤：&lt;/p>
&lt;ol>
&lt;li>&lt;code>用户浏览器中登录 -&amp;gt; tke-gateway -&amp;gt; tke-auth返回认证信息凭证 -&amp;gt; 设置访问凭证到浏览器&lt;/code>&lt;/li>
&lt;li>&lt;code>已有访问凭证的前端 -&amp;gt; tke-gateway -&amp;gt; tke-xxxx -&amp;gt; tke-auth校验认证凭证&lt;/code>&lt;/li>
&lt;/ol>
&lt;p>整个认证过程中数据传输都是通过浏览器或是 TKEStack 系统组件完成的，没有 kube-apiserver 的参与。&lt;/p>
&lt;h3 id="鉴权">鉴权&lt;/h3>
&lt;p>当前版本 TKEStack 系统组件的鉴权模式默认是以 &lt;a href="https://kubernetes.io/docs/reference/access-authn-authz/authorization/">SubjectAccessReview&lt;/a> 继承了 kube-apiserver 的鉴权模式，而 kube-apiserver 中鉴权模式配置了 webhook 指向了 tke-auth 组件。&lt;/p>
&lt;p>tke-auth 中的鉴权是基于 &lt;a href="https://github.com/casbin/casbin">casbin&lt;/a> 实现的，基于其 PERM 模型 TKEStack 完成了一套 RBAC 模型的实现：&lt;/p>
&lt;pre>&lt;code>[request_definition]
r = sub, dom, obj, act
[policy_definition]
p = sub, dom, obj, act, eft
[role_definition]
g = _, _, _
[policy_effect]
e = some(where (p.eft == allow)) &amp;amp;&amp;amp; !some(where (p.eft == deny))
[matchers]
m = g(r.sub, p.sub, r.dom) &amp;amp;&amp;amp; keyMatchCustom(r.obj, p.obj) &amp;amp;&amp;amp; keyMatchCustom(r.act, p.act)
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>request_definition：定义了模型的 Request&lt;/li>
&lt;li>policy_definition：定义了模型的 Policy&lt;/li>
&lt;li>role_definition：定义了模型的用户和角色的映射关系， 三个空缺分别表示用户, 角色, 域，TKEStack 使用的域为业务 ID&lt;/li>
&lt;li>policy_effect：定义了模型的 Effect&lt;/li>
&lt;li>matchers：定义了模型的匹配方式，keyMatchCustom 为自定义匹配函数，支持以正则匹配和通配符的方式，匹配 Role 和 Policy 的字段&lt;/li>
&lt;/ul>
&lt;p>用户通过浏览器访问场景下 TKEStack 的鉴权流程整个链路如下：&lt;/p>
&lt;p>&lt;code>用户浏览器发起请求 -&amp;gt; tke-gateway -&amp;gt; tke-xxx -&amp;gt; kube-apiserver webhook -&amp;gt; tke-auth返回鉴权结果&lt;/code>&lt;/p>
&lt;h2 id="集群内由-kubectl-发起的请求">集群内由 kubectl 发起的请求&lt;/h2>
&lt;h3 id="认证-1">认证&lt;/h3>
&lt;p>集群内通过 kubectl 发起请求场景下的认证流程与 K8s 本身的认证流程基本无异，因此整个链路也非常简单：&lt;/p>
&lt;p>&lt;code>kubectl 读取 kubeconfig 中的认证信息 -&amp;gt; kube-apiserver 检验认证信息&lt;/code>&lt;/p>
&lt;p>由于此场景下的用户信息是可以被 K8s 识别的，且 kubectl 是直接连接 kube-apiserver 的，认证流程在请求到达 TKEStack 系统组件之前就完成了。&lt;/p>
&lt;h3 id="鉴权-1">鉴权&lt;/h3>
&lt;p>之前在由浏览器发起访问场景中已经提到 TKEStack 系统组件的鉴权模式是以 &lt;a href="https://kubernetes.io/docs/reference/access-authn-authz/authorization/">SubjectAccessReview&lt;/a> 继承了 kube-apiserver 的鉴权模式，这种模式也同样适用于集群内由 kubectl 发起请求的场景，只不过在 kube-apiserver 中生效的鉴权模式不再是指向 tke-auth 的 webhook，而是 K8s 的 RBAC/ABAC 模式。&lt;/p>
&lt;p>整个鉴权流程的链路如下：&lt;/p>
&lt;p>&lt;code>kubectl 发起请求 -&amp;gt; kube-apiserver -&amp;gt; tke-xxx -&amp;gt; kube-apiserver 返回 RBAC/ABAC 鉴权结果&lt;/code>&lt;/p>
&lt;p>[1] Kubernetes 用户认证 [https://kubernetes.io/zh/docs/reference/access-authn-authz/authentication/]&lt;/p>
&lt;p>[2] Kubernetes 鉴权概述 [https://kubernetes.io/zh/docs/reference/access-authn-authz/authorization/]&lt;/p>
&lt;p>[3] Casbin 概述 [https://casbin.org/docs/zh-CN/overview]&lt;/p>
&lt;p>[4] Kubernetes API Aggregation Layer [https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/apiserver-aggregation/]&lt;/p></description></item><item><title>Blog: TKEStack 集群容器运行时迁移</title><link>/web/zh/blog/2021/09/01/container-runtime-migraion/</link><pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate><guid>/web/zh/blog/2021/09/01/container-runtime-migraion/</guid><description>
&lt;p>&lt;strong>Author&lt;/strong>: LeoRyu&lt;/p>
&lt;p>&lt;em>Kubernetes宣布在1.20版本之后将弃用Docker作为容器运行时，在2021年末发布的1.23版本中将彻底移除dockershim组件。可能很多朋友不是很清楚容器运行时迁移工作要怎么做，本文将就TKEStack的global集群如何进行容器运行时迁移做详细介绍。同时，本文非TKEStack globa集群的容器运行时迁移也有很好的参考价值。&lt;/em>&lt;/p>
&lt;h2 id="限制条件">限制条件&lt;/h2>
&lt;ol>
&lt;li>集群迁移前请确认master节点不止一个，单master节点切换容器运行时只能通过备份etcd数据再恢复集群方式，本文提供方法并不适用。&lt;/li>
&lt;li>迁移前倾确认当前K8s集群支持以containerd作为容器运行时，这里建议集群版本为1.19+。&lt;/li>
&lt;/ol>
&lt;h2 id="迁移流程">迁移流程&lt;/h2>
&lt;h3 id="准备工作">准备工作&lt;/h3>
&lt;ol>
&lt;li>每个节点上修改 docker daemon.json: &lt;code>vim /etc/docker/daemon.json&lt;/code>，将 &lt;code>&amp;quot;live-restore&amp;quot;&lt;/code> 修改为 &lt;code>false&lt;/code>。&lt;/li>
&lt;li>每个节点重启 dcoker 服务： &lt;code>systemctl daemon-reload &amp;amp;&amp;amp; systemctl restart docker.service&lt;/code>。&lt;/li>
&lt;li>修改galaxy ds：&lt;code>kubectl edit -n kube-system ds galaxy-daemonset&lt;/code>，在&lt;code>volumeMounts&lt;/code>和&lt;code>volumes&lt;/code>中添加以下内容：&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">...
volumeMounts:
- name: containerd-run
mountPropagation: Bidirectional
mountPath: /var/run/netns/
...
volumes:
- name: containerd-run
hostPath:
path: /var/run/netns
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="非master0节点迁移">非master0节点迁移&lt;/h3>
&lt;p>非global集群首个master节点的迁移步骤。&lt;/p>
&lt;ol>
&lt;li>封锁节点：&lt;code>kubectl cordon xxx&lt;/code>。&lt;/li>
&lt;li>驱逐节点：&lt;code>kubectl drain xxx --ignore-daemonsets --delete-local-data&lt;/code>，注意该操作会删除 &lt;code>pod&lt;/code> 的本地临时数据。&lt;/li>
&lt;li>停止Kubelet服务: &lt;code>systemctl stop kubelet&lt;/code>。&lt;/li>
&lt;li>停止Docker服务：&lt;code>systemctl disable docker.service &amp;amp;&amp;amp; systemctl stop docker.service &amp;amp;&amp;amp; systemctl stop containerd.service&lt;/code>。&lt;/li>
&lt;li>下载containerd，这里从 &lt;code>https://github.com/containerd/nerdctl/releases&lt;/code> 下载：&lt;code>curl -LO https://github.com/containerd/nerdctl/releases/download/v0.11.1/nerdctl-full-0.11.1-linux-amd64.tar.gz&lt;/code>。&lt;/li>
&lt;li>安装containerd：&lt;code>tar Cxzvvf /usr/local nerdctl-full-0.11.1-linux-amd64.tar.gz&lt;/code>。&lt;/li>
&lt;li>添加containerd自定义配置：&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">cat /etc/containerd/config.toml
&lt;span style="color:#000">version&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">2&lt;/span>
&lt;span style="color:#000">root&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;/var/lib/containerd&amp;#34;&lt;/span>
&lt;span style="color:#000">state&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;/run/containerd&amp;#34;&lt;/span>
&lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>grpc&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>
&lt;span style="color:#000">address&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;/run/containerd/containerd.sock&amp;#34;&lt;/span>
&lt;span style="color:#000">gid&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;span style="color:#000">max_recv_message_size&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">16777216&lt;/span>
&lt;span style="color:#000">max_send_message_size&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">16777216&lt;/span>
&lt;span style="color:#000">uid&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>plugins&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>
&lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>plugins.&lt;span style="color:#4e9a06">&amp;#34;io.containerd.grpc.v1.cri&amp;#34;&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>
&lt;span style="color:#000">sandbox_image&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;registry.tke.com/library/pause:3.2&amp;#34;&lt;/span>
&lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>plugins.&lt;span style="color:#4e9a06">&amp;#34;io.containerd.grpc.v1.cri&amp;#34;&lt;/span>.cni&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>
&lt;span style="color:#000">bin_dir&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;/opt/cni/bin&amp;#34;&lt;/span>
&lt;span style="color:#000">conf_dir&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;/etc/cni/net.d&amp;#34;&lt;/span>
&lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>plugins.&lt;span style="color:#4e9a06">&amp;#34;io.containerd.grpc.v1.cri&amp;#34;&lt;/span>.containerd&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>
&lt;span style="color:#000">default_runtime_name&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;runc&amp;#34;&lt;/span>
&lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>plugins.&lt;span style="color:#4e9a06">&amp;#34;io.containerd.grpc.v1.cri&amp;#34;&lt;/span>.registry&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>
&lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>plugins.&lt;span style="color:#4e9a06">&amp;#34;io.containerd.grpc.v1.cri&amp;#34;&lt;/span>.registry.configs&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>
&lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>plugins.&lt;span style="color:#4e9a06">&amp;#34;io.containerd.grpc.v1.cri&amp;#34;&lt;/span>.registry.configs.&lt;span style="color:#4e9a06">&amp;#34;registry.tke.com&amp;#34;&lt;/span>.tls&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>
&lt;span style="color:#000">insecure_skip_verify&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#204a87">true&lt;/span>
&lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>plugins.&lt;span style="color:#4e9a06">&amp;#34;io.containerd.grpc.v1.cri&amp;#34;&lt;/span>.registry.configs.&lt;span style="color:#4e9a06">&amp;#34;default.registry.tke.com&amp;#34;&lt;/span>.tls&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>
&lt;span style="color:#000">insecure_skip_verify&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#204a87">true&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="8">
&lt;li>修改 &lt;code>kubelet&lt;/code> 参数：&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">cat /usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf
&lt;span style="color:#8f5902;font-style:italic"># Note: This dropin only works with kubeadm and kubelet v1.11+&lt;/span>
&lt;span style="color:#ce5c00;font-weight:bold">[&lt;/span>Service&lt;span style="color:#ce5c00;font-weight:bold">]&lt;/span>
&lt;span style="color:#000">Environment&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf&amp;#34;&lt;/span>
&lt;span style="color:#000">Environment&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;KUBELET_CONFIG_ARGS=--config=/var/lib/kubelet/config.yaml&amp;#34;&lt;/span>
&lt;span style="color:#000">Environment&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;KUBELET_RUNTIME_ARGS=--container-runtime=remote --container-runtime-endpoint=unix:///run/containerd/containerd.sock&amp;#34;&lt;/span>
&lt;span style="color:#8f5902;font-style:italic"># This is a file that &amp;#34;kubeadm init&amp;#34; and &amp;#34;kubeadm join&amp;#34; generates at runtime, populating the KUBELET_KUBEADM_ARGS variable dynamically&lt;/span>
&lt;span style="color:#000">EnvironmentFile&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>-/var/lib/kubelet/kubeadm-flags.env
&lt;span style="color:#8f5902;font-style:italic"># This is a file that the user can use for overrides of the kubelet args as a last resort. Preferably, the user should use&lt;/span>
&lt;span style="color:#8f5902;font-style:italic"># the .NodeRegistration.KubeletExtraArgs object in the configuration files instead. KUBELET_EXTRA_ARGS should be sourced from this file.&lt;/span>
&lt;span style="color:#000">EnvironmentFile&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>-/etc/sysconfig/kubelet
&lt;span style="color:#000">ExecStart&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>
&lt;span style="color:#000">ExecStart&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>/usr/bin/kubelet &lt;span style="color:#000">$KUBELET_KUBECONFIG_ARGS&lt;/span> &lt;span style="color:#000">$KUBELET_CONFIG_ARGS&lt;/span> &lt;span style="color:#000">$KUBELET_KUBEADM_ARGS&lt;/span> &lt;span style="color:#000">$KUBELET_EXTRA_ARGS&lt;/span> &lt;span style="color:#000">$KUBELET_RUNTIME_ARGS&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="9">
&lt;li>
&lt;p>激活 &lt;code>containerd&lt;/code> 服务：&lt;code>systemctl daemon-reload &amp;amp;&amp;amp; systemctl enable containerd.service &amp;amp;&amp;amp; systemctl start containerd.service&lt;/code>。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>启动kubelet服务：&lt;code>systemctl daemon-reload &amp;amp;&amp;amp; systemctl start kubelet.service&lt;/code>。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>解除节点封锁：&lt;code>kubectl uncordon xxx&lt;/code>。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h3 id="master0节点迁移">master0节点迁移&lt;/h3>
&lt;p>如果你的集群不是TKEStack的global集群请忽略以下内容。如果你确定你当前的TKEStack没有使用内置的tke-registry作为镜像仓库，也可以忽略一下内容。&lt;/p>
&lt;p>不确定哪个是master0节点的话，可以通过&lt;code>kubectl get pod -n tke -owide | grep tke-registry-api&lt;/code>查看pod所在节点，该节点就是mater0节点。&lt;/p>
&lt;p>master0节点迁移放在其他节点迁移完成后在进行，相较非master0迁移多出了一下步骤：&lt;/p>
&lt;ol>
&lt;li>在步骤&lt;code>1. 封锁节点&lt;/code>前备份master0节点镜像到其他master节点：&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">&lt;span style="color:#8f5902;font-style:italic">## 使用docker在master0节点上执行：&lt;/span>
docker save &lt;span style="color:#204a87;font-weight:bold">$(&lt;/span>docker images &lt;span style="color:#000;font-weight:bold">|&lt;/span> sed &lt;span style="color:#4e9a06">&amp;#39;1d&amp;#39;&lt;/span> &lt;span style="color:#000;font-weight:bold">|&lt;/span> awk &lt;span style="color:#4e9a06">&amp;#39;{print $1 &amp;#34;:&amp;#34; $2}&amp;#39;&lt;/span>&lt;span style="color:#204a87;font-weight:bold">)&lt;/span> -o backup.tar
&lt;span style="color:#8f5902;font-style:italic">## 使用nerdctl在其他master节点上执行：&lt;/span>
nerdctl --namespace&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>k8s.io load -i backup.tar
&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="2">
&lt;li>在步骤&lt;code>9. 激活 &lt;/code>containerd&lt;code> 服务&lt;/code>之后，步骤&lt;code>10. 启动kubelet服务&lt;/code>之前加载master0节点镜像：&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">&lt;span style="color:#8f5902;font-style:italic">## 使用nerdctl在master0节点上执行：&lt;/span>
nerdctl --namespace&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>k8s.io load -i backup.tar
&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>Blog: TKEStack 容器混合云能力介绍（1）：统一基石</title><link>/web/zh/blog/2021/08/02/hybrid-cloud-introduction-1/</link><pubDate>Mon, 02 Aug 2021 00:00:00 +0000</pubDate><guid>/web/zh/blog/2021/08/02/hybrid-cloud-introduction-1/</guid><description>
&lt;p>&lt;strong>Author&lt;/strong>: LeoRyu, HuXiaoLiang&lt;/p>
&lt;p>&lt;em>随着云计算及云原生技术在各个领域内的逐步普及，基于 Kubernetes 的混合云相关概念和项目越来越受到人们的关注。以混合云形态部署企业的业务服务，在理论上可以最大化利用现有资源，形成差异互补和成本优化。以云计算及云原生技术作为基础设施的企业大致可以分为两类：一种是已经有存量 IDC 的企业，一种是业务全面使用公有云的企业。从已经有存量 IDC 的企业角度考虑，混合云可以最大化利用现有IDC资源的同时，既可以发挥 IDC 的灵活安全能力，也可以享受到公有云的高性价比优势；从业务全面使用公有云的企业角度考虑，混合云在为企业提供不同云服务商的差异能力的同时，也减少了企业绑定单一云服务商的潜在风险。尽管混合云的愿景是美好的，但走向这愿景的路并非简单。本文将着重介绍 TKEStack 提供混合云能力的道路上，在统一操作系统版本、 Kubernetes 版本、容器运行时和用户交互上遇到的困境与解决方案。&lt;/em>&lt;/p>
&lt;h2 id="不统一带来的问题">不统一带来的问题&lt;/h2>
&lt;h3 id="安全风险">安全风险&lt;/h3>
&lt;p>在 Linux 和 Kubernetes 受到广泛关注的今天，其安全问题的影响范围也越来越大。例如 2018 年爆出的特斯拉公司计算基础设施被黑客入侵用来挖矿的事件&lt;sup>[1]&lt;/sup>，就是因为特斯拉在亚马逊 AWS 上的 Kubernetes 容器集群访问权限没有得到妥善保护，导致存储在S3网络存储桶上的一些敏感技术数据，例如遥测技术，被窃取。&lt;/p>
&lt;p>根据 Palo Alto Networks 公司 Unit 42 团队的研究报告，在 2018 年 1 月至 2019 年 6 月之间，有2万多个基于 Kubernetes 的容器平台被暴露，下图为这些被暴露平台在全球范围内的统计数据&lt;sup>[2]&lt;/sup>：&lt;/p>
&lt;img alt="被暴露的平台统计" width="100%" src="exposed-k8s.png">
&lt;p>该报告中还统计了各云服务提供商平台上发现的漏洞：亚马逊 AWS 平台上被发现超过 2900 万个漏洞，谷歌云发现的漏洞数量接近 400 万，微软 Azure 发现了 170 万左右漏洞。&lt;/p>
&lt;p>这些漏洞分布在各种操作系统版本、Kubernetes 发行版本、容器运行时乃至用户交互的前端相关代码中。这些关键要素的不统一在客观上为这些安全漏洞提供了温床。&lt;/p>
&lt;h3 id="运维成本">运维成本&lt;/h3>
&lt;p>不统一也会使得用户的运维成本变得很高。例如当前 TKEStack 在混合云场景主推的网络方案 Cilium，其很多特性都要求在特定的内核版本以上才支持开启，下图是 Cilium 不同特性对内核版本要求的统计&lt;sup>[3]&lt;/sup>：&lt;/p>
&lt;img alt="Cilium特性内核版本要求" width="100%" src="required-kernel-version.png">
&lt;p>而 Kubernetes 版本尽管声明 patch 版本上下兼容，但实际上在各版本间 API 资源对象的转换方面可能存在兼容问题。例如 TKEStack 在升级 Kubernetes API 版本时就发现 &lt;code>url.Values&lt;/code> 隐式自动转换为 Kubernetes 对象已经被废弃&lt;sup>[4]&lt;/sup>，导致很多接口无法正常使用。&lt;/p>
&lt;p>随着业务的运行时间拉长和不断迭代，因为操作系统、Kubernetes、容器运行时和 UI 的不统一造成的运维成本，也会随着时间的推移越堆越高。&lt;/p>
&lt;h2 id="tkestack-社区为统一操作系统和-kubernetes-版本做出的努力">TKEStack 社区为统一操作系统和 Kubernetes 版本做出的努力&lt;/h2>
&lt;h3 id="推荐使用-tencentos-server">推荐使用 TencentOS Server&lt;/h3>
&lt;p>TencentOS Server 又名 Tencent Linux，简称 Tlinux 是腾讯针对云场景研发的 Linux 操作系统，提供了专门的功能特性和性能优化，为云服务器实例中的应用程序提供高性能，且更加安全可靠的运行环境&lt;sup>[5]&lt;/sup>。&lt;/p>
&lt;img alt="TencentOS" width="100%" src="tencentos-logo.png">
&lt;p>作为一个Linux发行版，Tlinux拥有以下优势：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>内核定制，基于内核社区长期支持的4.14.105版本定制而成，增加适用于云场景的新特性、改进内核性能并修复重大缺陷。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>容器支持，针对容器场景进行优化，提供了隔离增强和性能优化特性：meminfo、vmstat、cpuinfo、stat、loadavg, uptime, diskstats。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>性能优化，计算、存储和网络子系统均经过优化，包括：优化 xfs 内存分配，解决 xfs kmem_alloc 分配失败告警优化网络收包大内存分配问题，解决 UDP 包量大时，占据过多内存问题限制系统 page cache 占用内存比例，从而避免内存不足影响业务的性能或者 OOM。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>缺陷支持，提供操作系统崩溃后的 kdump 内核转储能力提供内核的热补丁升级能力。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>安全更新，会定期进行更新，增强安全性及功能。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>其他特性，离线调度算法(BT)、进程防gdb、ARM64热补丁、pagecache limit等。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>在混合云场景下 TKEStack 推荐使用 TencentOS Server 作为底层的操作系统，安全高效并提供了强大的云原生能力，关于 TencentOS Server 可以到项目网站 &lt;a href="https://github.com/Tencent/TencentOS-kernel">https://github.com/Tencent/TencentOS-kernel&lt;/a> 以了解更多内容。&lt;/p>
&lt;h3 id="引入-tke-发行版到-tkestack">引入 TKE 发行版到 TKEStack&lt;/h3>
&lt;p>长久以来，TKEStack 只提供了原生 Kubernetes 给用户使用，这使得 TKEStack 所能提供给用户的能力常常受到原生 Kubernetes 的现有能力的限制。为了打破这一现状，TKEStack 在前不久发布的 1.7 版本引入了由腾讯云 TKE 发布的 Kubernetes 发行版本，TKE 发行版（TKE Kubernetes Distro）。TKE 发行版在保证兼容性的基础上，对 K8s 进行了扩展，并且与腾讯云 TKE 服务保持版本一致。用户可以在自己的 IDC 或者混合云上部署 TKE 发行版，使用已有企业用户大规模验证的可靠安全的 Kubernetes 服务&lt;sup>[6]&lt;/sup>。&lt;/p>
&lt;img alt="TKE发行版" width="100%" src="tke-distro.png">
&lt;p>相比原生的 Kubernetes 版本，TKE 发行版优势有下面几项：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>大规模生产集群验证，TKE 发行版提供与腾讯云 TKE 相同的可安装版本和开源代码，功能和稳定性经过大量企业用户、公有云及自研云锤炼。用户可以使用提供的源代码和编译工具进行构建和部署。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>无缝集成公有云 TKE，TKE 发行版可支持用户在自建或者托管机房，物理机或者虚机上，运行与腾讯云 TKE 完全一致的 K8s 服务。并且可以无缝与腾讯云 TKE 集成，组建混合云集群。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>更长支持周期，TKE 发行版的支持周期比社区版更长。在社区版停止支持后，TKE 发行版将继续得到支持，包括重要问题以及安全漏洞的修复。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>更多实用能力增强，TKE 发行版结合腾讯自身业务特点和经验，针对部分场景（弹性扩容、离在线混部、资源隔离等）实现了能力增强。并且 TKE 发行版紧跟社区趋势，主导或深度参与社区 KEP 设计与实现。对于有实用价值 KEP 会先于社区支持，让用户提前享受到云原生技术进步。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>关于 TKE 发行版的更多信息可以访问 &lt;a href="https://github.com/tkestack/tke-k8s-distro">https://github.com/tkestack/tke-k8s-distro&lt;/a> 以进一步了解。&lt;/p>
&lt;p>在 1.7 版本中 TKEStack 支持 TKE 发行版本和原生两种 Kubernetes 发行版本，由于 TKE 发行版完全兼容原生 Kubernetes 发行版本，在后续的迭代中 TKEStack 将朝着只携带 TKE 发行版的方向逐步前进。&lt;/p>
&lt;h3 id="使用-containerd-作为容器运行时">使用 Containerd 作为容器运行时&lt;/h3>
&lt;p>2020 年年末，Kubernetes社区宣布预计最早将在2021年晚些时候发布的 1.23 版本中废弃dockershim&lt;sup>[7]&lt;/sup>，这意味着未来的 Kubernetes 将不再支持以 Docker 作为容器运行时。&lt;/p>
&lt;p>TKEStack 社区经过研讨调研后，决定使用和腾讯公有云 TKE 一致的 Containerd 作为未来替代 Docker 的容器运行时。Containerd 是除 Docker 外当下最为成熟稳定，并被广泛接受的容器运行时，下图是 2021 年年初关于容器运行时使用率相关的调查统计&lt;sup>[8]&lt;/sup>：&lt;/p>
&lt;img alt="运行时使用率" width="100%" src="container-runtimes.png">
&lt;p>Containerd 的架构是 client-server 架构，支持 runc、Kata Container 等多种底层运行时，同时又有很高的扩展性，下图为 Containerd 的整体架构图&lt;sup>[9]&lt;/sup>：&lt;/p>
&lt;img alt="containerd整体架构" width="100%" src="containerd-architecture.png">
&lt;p>作为过渡时期，如果用户选择的 Kubernetes 版本依旧支持 dockershim，TKEStack 将允许用户在创建集群时决定选择 Docker 还是 Containerd 作为容器运行时，并提供文档，帮助用户将存量集群的 runtime 从 Docker 迁移到 Containerd。未来，TKEStack会移除掉 Docker 的依赖，全面兼容社区的 CRI 标准模型，并将 Containerd 作为默认的 runtime 与公有云 TKE 保持统一。&lt;/p>
&lt;h3 id="风格统一的用户交互">风格统一的用户交互&lt;/h3>
&lt;p>统一的交互风格可以大大减少用户的学习成本和心智负担。TKEStack 与腾讯公有云 TKE 产品采用了相同的交互风格，用户只需要适应了其中一个的交互习惯，就可以几乎零学习成本的操作使用另外一款产品。下图展示了 TKEStack 和腾讯公有云 TKE 产品的用户前端交互页面：&lt;/p>
&lt;img alt="containerd整体架构" width="100%" src="tkestack-and-tke.png">
&lt;p>TKEStack 和腾讯公有云 TKE 产品上有着很多相同的概念，针对这些概念的视图展示逻辑也是一致的。在混合云场景下，这种一致性将产生积极的化学反应，对用户非常友好，并减轻了维护上的成本。&lt;/p>
&lt;p>交互的统一不仅仅对用户有很多好处，对后续 TKEStack 的产品设计，后台架构搭建及能力实现上都有着积极的作用，而这种积极作用会为 TKEStack 加速布局混合云领域提供有力的支持。&lt;/p>
&lt;h2 id="总结">总结&lt;/h2>
&lt;p>正所谓工欲善其事，必先利其器，只有统一巩固一个强大稳定的平台基石，TKEStack 才会在提供混合云能力的道路上行驶的更加平稳。后续我们会在该系列中介绍更多关于 TKEStack 的混合云能力，敬请大家期待。&lt;/p>
&lt;p>最后欢迎大家到 TKEStack 的项目仓库 &lt;a href="https://github.com/tkestack/tke">https://github.com/tkestack/tke&lt;/a> 提出建议贡献力量，大家的支持将会令 TKEStack 项目变得更好！&lt;/p>
&lt;h2 id="参考资料">参考资料&lt;/h2>
&lt;p>[1] Lessons from the Cryptojacking Attack at Tesla [https://redlock.io/blog/cryptojacking-tesla]&lt;/p>
&lt;p>[2] Cloudy with a Chance of Entropy [https://www.paloaltonetworks.com/resources/research/unit42-cloud-with-a-chance-of-entropy]&lt;/p>
&lt;p>[3] Required Kernel Versions for Advanced Features [https://docs.cilium.io/en/v1.10/operations/system_requirements/#required-kernel-versions-for-advanced-features]&lt;/p>
&lt;p>[4] Can no longer call DecodeParameters with url.Values in 1.19.0 client-go [https://github.com/kubernetes/kubernetes/issues/94688]&lt;/p>
&lt;p>[5] 腾讯TencentOS 十年云原生的迭代演进之路 [https://mp.weixin.qq.com/s/Cbck85WmivAW0mtMYdeEIw]&lt;/p>
&lt;p>[6] 腾讯云云原生混合云-TKE发行版 [https://mp.weixin.qq.com/s/d7ubPXwtTw8JsFIHp-JXEg]&lt;/p>
&lt;p>[7] Dockershim Deprecation FAQ [https://kubernetes.io/blog/2020/12/02/dockershim-faq/]&lt;/p>
&lt;p>[8] Sysdig 2021 container security and usage report: Shifting left is not enough [https://sysdig.com/blog/sysdig-2021-container-security-usage-report/]&lt;/p>
&lt;p>[9] Introduction and Deep Dive Into Containerd [https://static.sched.com/hosted_files/kccnceu2021/d3/containerd-KubeConEU2021.pdf]&lt;/p></description></item><item><title>Blog: 腾讯开源容器云平台 TKEStack 介绍</title><link>/web/zh/blog/2021/06/09/tkestack-indtroduction-2021/</link><pubDate>Wed, 09 Jun 2021 00:00:00 +0000</pubDate><guid>/web/zh/blog/2021/06/09/tkestack-indtroduction-2021/</guid><description>
&lt;p>&lt;strong>Author&lt;/strong>: Yingzhe Ru (汝英哲)&lt;/p>
&lt;p>&lt;em>2019年11月在腾讯 Techo 开发者大会上，TKEStack 正式发布并宣布开源， 同一时间凝结着腾讯多年来容器技术积累的代码也通过 push 命令上传到 github， 从那一刻起我们开启了一段面向开源，充满机遇与挑战，驶向未来云世界的伟大航程。 时间回到今天，TKEStack 自开源后已经过去了几个月，迭代了多个版本，当前仍在以较快的速度提交修改，发布更新。 随着开发进度的推进，产品的功能逐渐增强，用户体验愈发的完善，整个产品和技术栈的轮廓也愈加的清晰， 因此有必要在这里系统介绍一下 TKEStack 容器云平台，明确我们的目标，展示平台的特性以及为您提供的价值，希望您阅读完这篇文章后， 能够对 TKEStack 产生兴趣，了解到 TKEStack 的能力，并能够考虑使用或集成 TKEStack 助力您的业务或商业产品落地。&lt;/em>&lt;/p>
&lt;h2 id="简介">简介&lt;/h2>
&lt;p>近年来在云计算领域，容器技术领域不断创新，围绕容器以及容器相关技术构建出云原生的生态和技术标准。 基于 Kubernetes 的容器平台，为容器化的应用提供资源调度、部署运行、服务发现和弹性伸缩等整一套功能， 逐步成为客户软件基础设施的不二之选。&lt;/p>
&lt;p>腾讯在云计算领域深耕多年，尤其在容器技术领域，自2009年开发容器计算平台 T-Borg 开始，2012年开发内部的离线在线混合部署的容器平台 Torca，2013、2014年 Docker 和 Kubernetes 出现后，腾讯迅速切换自研方案到开源方案，对外推出商用公有云版本服务TKE和私有云版本 GaiaStack。2019年，公有云和私有云版本合并为统一架构和方案 TKE，并推出了社区发行版 TKEStack。&lt;/p>
&lt;p>TKEStack是腾讯内部几大团队合力打造的开源版本，总结了多年来腾讯在云原生领域的经验和技术积累，吸收了 Gaia 平台、TKE公有云以及腾讯内部众多容器产品的优点，全新打造的面向私有云业务场景的开源容器平台。TKEStack 以高起点起步，甩掉大量历史遗留包袱，从架构上重新设计，并且结合业内生态最新的更新和特性，使得TKEStack轻装上阵，用户开箱即用最新的云原生能力。&lt;/p>
&lt;p>TKEStack 名称中包含 Stack，也表明 TKEStack 有别于其他容器产品，它将打造的是一整套技术栈，以 TKE 容器平台为核心，面向网络，存储，应用，服务等各个领域，扩展平台在底层资源管控和上层业务服务上的能力边界，所有这些能力都将在 TKEStack 下开源，社区用户、合作伙伴等都可以参与进来贡献和分享。&lt;/p>
&lt;h2 id="愿景与目标">愿景与目标&lt;/h2>
&lt;p>未来云计算基础设施一定处于多维异构的状态，未来客户也会处于多维异构的业务场景，包括硬件异构、基础架构异构和业务平台异构。&lt;/p>
&lt;ul>
&lt;li>硬件异构 - 随着国产化在国内的发展，将来客户的服务器架构将会是 x86 和 arm64 混杂在一起；随着AI计算发展，Intel 等厂商也加入到 GPU 的竞争中，再加上 ARM 平台的 GPU 和 FPGA 等硬件，计算领域的硬件将更加碎片化。&lt;/li>
&lt;li>基础架构异构 - 未来的数字化计算服务中心，尤其在国内，将更多会采用私有化(或专有云)和公有云混合部署的模型支持业务发展。&lt;/li>
&lt;li>业务平台异构 - 传统业务在无法全部迁移下的情况，长期会和微服务、Service Mesh 、Serverless等技术组成一个异构的业务大中台，同时还要支撑使用 Spark、Hadoop、TensorFlow、PyTorch 等计算平台运行。&lt;/li>
&lt;/ul>
&lt;p>我们的愿景是为内部业务和外部商业客户提供离线计算业务和在线服务业务混合部署的一站式通用基础架构平台。 基于此愿景，TKEStack 将继承腾讯内部容器技术优势，为用户、为合作伙伴、为生态创造价值，生态共建，产业共创。&lt;/p>
&lt;ul>
&lt;li>面向用户 - 为用户提供稳定高效可扩展的容器服务产品，提供便捷的安装部署、简洁的管控和资源管理，以及完善的运维工具支持，满足业务上云需求。&lt;/li>
&lt;li>面向合作伙伴 - 为下游产品提供调度能力强大、功能丰富、性能稳定的容器底座，使用户能基于 TKEStack 便捷打造易部署、易维护、易扩展的产品和服务，在互联网、传统行业与政企等领域提供有针对性的行业解决方案。&lt;/li>
&lt;li>面向生态 - 围绕容器生态的各种能力，统一应用服务的定义，发布、配置、升级及运维整个生命周期管理，整合中间件、运行时、存储、网络能力，逐步建立起一个基于云原生的容器平台标准。&lt;/li>
&lt;/ul>
&lt;h2 id="整体架构">整体架构&lt;/h2>
&lt;p>TKEStack整体架构上采用 Kubernetes on Kubernetes 的设计理念，充分满足平台服务的高可用性和扩展性。&lt;/p>
&lt;img alt="TKEStack整体架构" width="100%" src="tkestack_ infrastructure.png">
&lt;ul>
&lt;li>Global: 集群负责运行整个 TKEStack 平台自身所需组件；&lt;/li>
&lt;li>Cluster: 业务集群是由 TKEStack 控制台统一管理，负责运行业务；&lt;/li>
&lt;li>Installer: 负载安装 Global 集群和管控组件；&lt;/li>
&lt;li>Auth: 权限认证组件，提供用户认证、授权相关功能；&lt;/li>
&lt;li>Gateway: 网关组件，并运行控制台的 Web 界面服务；&lt;/li>
&lt;li>Platform: 平台管理组件，提供包含集群管理等功能的平台服务；&lt;/li>
&lt;li>Business: 业务管理组件，提供业务管理相关功能的后台服务；&lt;/li>
&lt;li>Monitor: 监控服务组件，提供监控采集、上报、告警相关服务；&lt;/li>
&lt;li>Notify: 通知功能组件，提供消息通知相关的功能；&lt;/li>
&lt;li>Registry: 镜像服务组件，提供平台镜像仓库和 charts 仓库服务；&lt;/li>
&lt;li>Galaxy: 网络插件，为集群提供多种网络模式服务；&lt;/li>
&lt;li>Logagent: 日志管理组件，为平台提供日志管理相关服务；&lt;/li>
&lt;li>Audit: 设计组件，提供审计服务功能；&lt;/li>
&lt;/ul>
&lt;p>Global 集群提供容器云平台的支撑环境和运行自身所需的各种组件，包括业务管理组件、平台管理组件、权限认证组件、监控和告警组件、registry 镜像仓库组件以及 gateway 前端页面网关组件等等。各个组件以 workload 的形式灵活部署在 global 集群中，各组件多副本高可用方式部署，单个组件异常或者主机节点掉线等故障不会影响global集群的正常运行，TKEStack仍可提供的管理功能，用户正常的业务访问不受影响。&lt;/p>
&lt;p>在扩展性方面，根据不同场景灵活配置集群，例如为承载大流量高可靠性的在线业务，有必要提高 global 集群的规格配置，使其能够管理大规模海量的业务集群及应用资源；如果面向个人开发者或中小型业务，甚至可以简化为仅数个节点组成的 global 集群，并通过该集群承载业务。&lt;/p>
&lt;h2 id="能力特性">能力特性&lt;/h2>
&lt;p>通过集成和使用 TKEStack，不仅支持 K8S 原生的资源调度、部署运行、服务发现和弹性伸缩等整一套功能，TKEStack 还支持多种特性，方便用户接入和使用，通过灵活的扩展功能实现自身服务的增值。&lt;/p>
&lt;h3 id="原生支持">原生支持&lt;/h3>
&lt;p>TKEStack是一款专注于 Kubernetes 技术栈的，集易用性与扩展性于一身的 K8S 发行版，符合Kubernetes接口标准，产品底层完全兼容标准 Kubernetes。因此，基于 Kubernetes 生态的应用和服务都可以无缝迁移到TKEStack上来，有标准K8S运维管理经验的用户可以平滑的切换到 TKEStack 平台。&lt;/p>
&lt;p>TKEStack 跟随最新 k8s 版本，支持所有可用的功能和安全补丁，通过灵活的集群管理功能，方便的对集群进行更新升级操作，帮助用户体验和使用最新的生态技术。作为云原生的基础设施平台，任何符合云原生规范和标准的应用或项目，都可以构建和运行在 TKEStack 中。&lt;/p>
&lt;h3 id="简单易用">简单易用&lt;/h3>
&lt;p>提供和腾讯公有云版一致的 UI，界面简洁友好，支持配置各种 K8S 资源，方便用户顺利的创建和管理容器应用，降低了容器平台的学习和操作成本。TKEStack 还有着完善的镜像仓库和应用商店功能，内部包含腾讯优秀的开源容器应用模板，方便用户一键部署高质量稳定的应用服务。&lt;/p>
&lt;h3 id="多集群管理">多集群管理&lt;/h3>
&lt;p>支持新建独立集群或纳管不同基础设施上的已有 Kubernetes 集群，通过页面或命令行集中管理多个集群，实现了混合云场景下的多集群统一管理能力。只需提供需要管理集群的 api 地址，token 和 ca 证书，TKEStack 就可以纳管该集群。纳管操作不会污染导入的集群，被纳管集群不会增加额外的负载或配置。统一一致的用户权限及业务管理等功能帮助用户在集群间灵活切换，方便的部署和管理多集群应用。&lt;/p>
&lt;img alt="多集群管理" width="100%" src="mutil_cluster_management.png">
&lt;p>更多信息请参考&lt;a href="https://tkestack.github.io/docs/user-guide/platform-console/cluster-mgmt.html">集群管理&lt;/a>&lt;/p>
&lt;h3 id="多租户管理">多租户管理&lt;/h3>
&lt;p>支持多租户管理和租户间隔离，不仅仅局限于账号，而是包括集群、命名空间、业务、镜像仓库等等，满足大中型规模企业管理的需求。并且在租户层次之下，拥有业务的概念，业务可以横跨集群，为用户提供统一的配额管理、命名空间、业务配额以及镜像仓库和应用商店等管理能力，方便用户在多集群场景下编排业务应用。&lt;/p>
&lt;img alt="多租户管理" width="100%" src="mutil_tenant_management.png">
&lt;p>TKEStack提供统一和开放的认证授权管理，通过扩充 kubernetes 的 authz 和 authn 的 webhook，实现所有集群无需单独配置 RBAC，为上层提供统一的可跨集群的资源授权。TKEStack自身的认证和授权体系是完整的 K8S Style API 以及 oidc 认证协议支持，可以很容易的由第三方集成商或开发者集成在自身的产品中，实现和 TKEStack 捆绑服务。企业级用户可以方便的将已有的账户体系或组织架构映射到 TKEStack 平台中，从而节省容器平台对接的工作量，专注于自身高价值业务的开发。&lt;/p>
&lt;p>更多信息请参考&lt;a href="https://tkestack.github.io/docs/user-guide/platform-console/access-mgmt/">访问管理&lt;/a>&lt;/p>
&lt;h3 id="运维友好的管理平台">运维友好的管理平台&lt;/h3>
&lt;p>TKEStack 致力于打造一个运维友好的管理平台，帮助运维人员从繁杂的劳动中解放出来。TKEStack 提供完整详细的监控及日志服务，粒度精细到对集群下每一个容器每一条日志都有监控和记录。并且提供智能化的安装工具、巡检工具，帮助运维人员对整个平台全程进行管理，提前发现风险点，提高系统的可靠性。&lt;/p>
&lt;h4 id="快捷安装">快捷安装&lt;/h4>
&lt;p>TKEStack 使用 tke-installer 安装工具进行安装，通过界面化的方式引导用户一键部署 TKEStack 容器平台。tke-installer 安装工具能够检查基本的环境信息，自动适配 x86 或 arm 版本安装驱动和镜像。离线的安装方式更免去用户拉取镜像的烦恼，极大的提高了容器平台部署的效率。&lt;/p>
&lt;img alt="安装流程" width="100%" src="install_process.png">
&lt;p>tke-installer 自动等待和检查每一步骤安装完成，如果中间过程出错会自动在日志界面提示相应的信息，并支持根据用户需要，选择全新安装或从失败步骤继续安装。更支持以 hook 方式自定义安装流程，用户可以在安装开始前、集群 ready 后以及安装结束后三个 hook 点添加自己的脚本或命令，实现平台安装的可定制化。&lt;/p>
&lt;p>更多安装信息请见：&lt;a href="https://github.com/tkestack/tke/tree/master/docs/guide/zh-CN/installation">TKEStack安装说明&lt;/a>&lt;/p>
&lt;h4 id="监控系统">监控系统&lt;/h4>
&lt;p>免去部署和配置 prometheus 的复杂操作，TKEStack 提供高可用性和可扩展性的细粒度监控系统，实时监控 CPU，GPU，内存，显存，网络带宽，磁盘io等多种指标并自动绘制趋势曲线，帮助运维人员全维度的掌握平台运行状态。&lt;/p>
&lt;img alt="监控系统" width="100%" src="monitor.png">
&lt;p>TKEStack通过prometheus组件监控集群状态，prometheus 组件通过 addon 扩展组件自动完成安装和配置，使用 influxdb，elasticsearch 等存储监控数据。监控数据和指标融入到平台界面中以风格统一图表的风格展示，支持以不同时间，粒度等条件，查询集群，节点，业务，workload以及容器等多个层级的监控数据，全维度的掌握平台运行状态。&lt;/p>
&lt;p>同时针对在可用性和可扩展性方面，支持使用 thanos 架构提供可靠的细粒度监控和警报服务，构建具有高可用性和可扩展性的细粒度监控能力。&lt;/p>
&lt;p>详情请见&lt;a href="https://mp.weixin.qq.com/s/Kn4RACzihWGoajV1Q0G_cA">thanos架构介绍&lt;/a>&lt;/p>
&lt;h4 id="日志服务">日志服务&lt;/h4>
&lt;p>提供的集群内日志采集功能，支持将集群内服务或集群节点特定路径文件的日志发送至 Kafka、Elasticsearch等消费端，支持采集容器标准输出日志，容器内文件日志以及主机内文件日志。更提供事件持久化、审计等功能，实时记录集群事件及操作日志记录，帮助运维人员存储和分析集群内部资源生命周期、资源调度、异常告警等情况。&lt;/p>
&lt;img alt="日志服务" width="100%" src="log.png">
&lt;p>需要为每个集群手动开启日志采集功能。日志采集功能开启后，log-collector 会在集群内以 DaemonSet 的形式运行，并根据用户通过日志采集规则配置的采集源和消费端，从采集源进行日志采集，将日志内容发送到消费端。&lt;/p>
&lt;ul>
&lt;li>采集容器标准输出日志 - 采集集群内指定容器的标准输出日志，采集到的日志信息将会以 JSON 格式输出到用户指定的消费端，并会自动附加相关的 Kubernetes metadata， 包括容器所属 pod 的 label 和 annotation 等信息。&lt;/li>
&lt;li>采集容器内文件日志 - 采集集群内指定 pod 内文件的日志，用户可以根据自己的需求，灵活的配置所需的容器和路径，采集到的日志信息将会以 JSON 格式输出到用户指定的消费端， 并会附加相关的 Kubernetes metadata，包括容器所属 pod 的 label 和 annotation 等信息。&lt;/li>
&lt;li>采集主机内文件日志 - 采集集群内所有节点的指定主机路径的日志，log-collector 会采集集群内所有节点上满足指定路径规则的文件日志，以 JSON 格式输出到用户指定的输出端， 并会附加用户指定的 metadata，包括日志来源文件的路径和用户自定义的 metadata。&lt;/li>
&lt;/ul>
&lt;p>更多日志信息请参考&lt;a href="https://tkestack.github.io/docs/user-guide/platform-console/operation-mgmt/log-collect.html">日志管理&lt;/a>&lt;/p>
&lt;h4 id="平台巡检">平台巡检&lt;/h4>
&lt;p>巡检工具 kube-javis，通过 plugin 插件的方式灵活配置和扩展，多维度的检查 TKEStack 平台下集群的健康状况，支持集成到 TKEStack 平台中，定期运行并输出诊断结果和修复建议。&lt;/p>
&lt;p>更多详细信息请关注&lt;a href="https://github.com/tkestack/kube-jarvis">kube-javis&lt;/a>&lt;/p>
&lt;h3 id="扩展组件支持和管理">扩展组件支持和管理&lt;/h3>
&lt;p>Tkestack 的特色功能，以扩展组件的方式来订制集群的能力，扩展集群的功能。TKEStack 已支持多种扩展组件，包含：&lt;/p>
&lt;ul>
&lt;li>GPUManager - GPU Manager 提供一个 All-in-One 的 GPU 管理器, 基于K8S Device Plugin插件系统实现, 提供了 GPU 虚拟化、拓扑分配、GPU 共享、GPU 指标查询、GPU 容器 pre-check 等功能, 支持用户在 K8S 集群中高效的使用 GPU 设备。&lt;/li>
&lt;li>TApp - Tapp 是结合腾讯十多年海量运营经验，全新设计出的一种 workload，以 CRD 的形式实现。 Tapp可运行有状态、无状态应用，弥补了 StatefulSet 无法批量更新容器的不足，使用方式兼容传统运维习惯，更好的支持传统的有状态应用，能够实现灰度升级和多版本的发布管理。&lt;/li>
&lt;li>CronHPA - 使用 crontab 模式定期自动扩容工作负载，周期性地在给定的调度时间对工作负载进行扩缩容。&lt;/li>
&lt;li>LBCF - 一款通用负载均衡控制面框架，对K8S内部晦涩的运行机制进行了封装并以 Webhook 的形式对外暴露，并提供强大的扩展能力以满足业务方在使用负载均衡时的个性化需求。&lt;/li>
&lt;li>CSIOperator - 负责 CSI 相关组件的部署与维护，帮助用户在集群中使用存储。&lt;/li>
&lt;li>IPAM - 通过 IPAM 扩展组件安装，扩展了 K8S 调度插件，实现 Float IP 的配置和管理，满足复杂应用容器化的特殊需求。&lt;/li>
&lt;/ul>
&lt;p>更多详情请参考&lt;a href="https://tkestack.github.io/docs/key-features/">扩展组件&lt;/a>&lt;/p>
&lt;h2 id="总结">总结&lt;/h2>
&lt;p>随着2020年3月国家发改委进一步明确了包括以云计算等为代表的新技术基础设施纳入“新基建”的范围，国内云计算市场将迎来一波建设的热潮。尤其在私有云领域，传统行业企业基本开始了业务的云迁移，但其应用系统的弹性、自动化运维管理能力以及 Devops 和持续交付的能力仍在不断的探索和尝试，迫切的需要一套成熟的产品平台和生态体系，帮助企业完成云原生转型。&lt;/p>
&lt;p>开源TKEStack的推出，将推动企业业务向云原生的转型，提供完善的容器产品功能，打造运维友好的管理平台，减少用户繁复的劳动，提高工作效率。完善的API和租户管理能力，方便用户将已有的账户体系或组织架构映射到TKEStack平台中，节省平台业务对接的工作量。并且良好的扩展能力使得用户能够基于 TKEStack 适配本地基础设施，扩展业务所需的各种能力。&lt;/p>
&lt;p>TKEStack 已在腾讯内部大量使用，总结积累了大量经验和技术，持续进行迭代开发，不断完善功能特性，并且第一时间将成果贡献给社区，帮助用户紧跟云原生潮流，享用最新技术能力，同时免除了被技术绑定的风险。我们希望通过 TKEStack 的稳定高效和灵活扩展的平台能力，帮助您构建以 TKEStack 为底座的，适配各种硬件架构和基础环境的，面向 AI、大数据、中间件以及微服务等等多种场景的服务，在互联网、传统行业与政企等领域，联合合作伙伴提供有针对性的行业解决方案。TKEStack 仍在不断的成长中，后续我们还会开发更多的功能，输出更多腾讯内部优秀的产品和能力。&lt;/p>
&lt;p>最后，感谢您的时间，希望你在读完文章后，能够了解到 TKEStack 容器云平台，希望 TKEStack 能够成为您的选择， 我们愿与您一道前行，创造价值，加速创新，共建云生态，一起迈向未来云世界。&lt;/p></description></item></channel></rss>